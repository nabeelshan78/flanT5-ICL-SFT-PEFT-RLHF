{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f567cbd4",
      "metadata": {
        "id": "f567cbd4"
      },
      "source": [
        "# **Fine-Tune FLAN-T5 with Reinforcement Learning (PPO) and PEFT to Generate Less-Toxic Summaries**\n",
        "\n",
        "Fine-Tuning a `FLAN-T5` model using **Proximal Policy Optimization (PPO)** and **Parameter-Efficient Fine-Tuning (PEFT)** to generate **less toxic summaries** of dialogues. A **reward model** based on Meta AI\u2019s **RoBERTa hate speech classifier** is used to guide the fine-tuning process. The key objective is to encourage the model to produce **non-toxic, safe summaries**.\n",
        "\n",
        "### Goal\n",
        "\n",
        "- Load a summarization dataset (`DialogSum`) and a pre-trained `FLAN-T5` model.\n",
        "- Use a **hate speech classifier** as a **reward model** to guide detoxification.\n",
        "- Apply **Reinforcement Learning with PPO** on top of **LoRA-based PEFT**.\n",
        "- Compare toxicity scores before and after fine-tuning using Hugging Face `evaluate`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74bfd06e-c747-43e0-b86c-0398628e1c32",
      "metadata": {
        "id": "74bfd06e-c747-43e0-b86c-0398628e1c32"
      },
      "source": [
        "Import the necessary packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install transformers datasets peft trl torch evaluate numpy pandas tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d8c20bed-6a30-4847-a507-02969ecb4465",
      "metadata": {
        "id": "d8c20bed-6a30-4847-a507-02969ecb4465"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM, GenerationConfig\n",
        "from datasets import load_dataset, load_from_disk\n",
        "from peft import PeftModel, PeftConfig, LoraConfig, TaskType\n",
        "\n",
        "# trl: Transformer Reinforcement Learning library\n",
        "from trl import PPOTrainer, PPOConfig, AutoModelForSeq2SeqLMWithValueHead\n",
        "from trl import create_reference_model\n",
        "from trl.core import LengthSampler\n",
        "\n",
        "import torch\n",
        "import evaluate\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b76eea84-8e3a-4487-9692-613977e6c8e3",
      "metadata": {
        "id": "b76eea84-8e3a-4487-9692-613977e6c8e3"
      },
      "source": [
        "## Load FLAN-T5 Model, Fine-Tuned Peft Adapter,  Prepare Reward Model and Toxicity Evaluator"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a5f97d4-ea5f-4072-b5d6-785d1d833ed4",
      "metadata": {
        "id": "4a5f97d4-ea5f-4072-b5d6-785d1d833ed4"
      },
      "source": [
        "### Load Data and FLAN-T5 Model Fine-Tuned with Summarization Instruction\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b058b52b-ec4d-4426-8d71-91e898f727f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b058b52b-ec4d-4426-8d71-91e898f727f6",
        "outputId": "214a04c2-1563-44e8-9250-f34c45241883"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 12460\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 500\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 1500\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_path = \"flan-t5-base\"\n",
        "dataset_path = \"dialogsum_dataset\"\n",
        "\n",
        "dataset_original = load_from_disk(dataset_path)\n",
        "dataset_original"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today?\n",
            "#Person2#: I found it would be a good idea to get a check-up.\n",
            "#Person1#: Yes, well, you haven't had one for 5 years. You should have one every year.\n",
            "#Person2#: I know. I figure as long as there is nothing wrong, why go see the doctor?\n",
            "#Person1#: Well, the best way to avoid serious illnesses is to find out about them early. So try to come at least once a year for your own good.\n",
            "#Person2#: Ok.\n",
            "#Person1#: Let me see here. Your eyes and ears look fine. Take a deep breath, please. Do you smoke, Mr. Smith?\n",
            "#Person2#: Yes.\n",
            "#Person1#: Smoking is the leading cause of lung cancer and heart disease, you know. You really should quit.\n",
            "#Person2#: I've tried hundreds of times, but I just can't seem to kick the habit.\n",
            "#Person1#: Well, we have classes and some medications that might help. I'll give you more information before you leave.\n",
            "#Person2#: Ok, thanks doctor.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Mr. Smith's getting a check-up, and Doctor Hawkins advises him to have one every year. Hawkins'll give some information about their classes and medications to help Mr. Smith quit smoking.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "get a check-up\n"
          ]
        }
      ],
      "source": [
        "sample = dataset_original[\"train\"][0]\n",
        "print(sample[\"dialogue\"])\n",
        "print(\"-\" * 100)\n",
        "print(sample[\"summary\"])\n",
        "print(\"-\" * 100)\n",
        "print(sample[\"topic\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "668d30d6-6f81-4e52-a81a-3057163ddb0e",
      "metadata": {
        "id": "668d30d6-6f81-4e52-a81a-3057163ddb0e"
      },
      "source": [
        "Preprocessing the dataset. Wraping each dialogue with the instruction and tokenize the prompts. Save the token ids in the field `input_ids` and decoded version of the prompts in the field `query`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# tokenizer = AutoTokenizer.from_pretrained('flan-t5-base/', device_map=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# tokenizer.encode(\"How are you?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(tokenizer.decode([571, 33, 25, 58, 1], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "51469abe-4d72-4093-a6c6-8e04e19f09eb",
      "metadata": {
        "id": "51469abe-4d72-4093-a6c6-8e04e19f09eb"
      },
      "outputs": [],
      "source": [
        "def build_dataset(model_path,\n",
        "                  dataset_path):\n",
        "\n",
        "    \"\"\"\n",
        "    Preprocess the dataset\n",
        "\n",
        "    Parameters:\n",
        "    - model_name (str): Tokenizer model name.\n",
        "    - dataset_name (str): Name of the dataset to load.\n",
        "\n",
        "    Returns:\n",
        "    - dataset_splits (datasets.dataset_dict.DatasetDict): Preprocessed dataset containing train val test parts.\n",
        "    \"\"\"\n",
        "\n",
        "    dataset = load_from_disk(dataset_path)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path, device_map=device)\n",
        "\n",
        "    def tokenize(sample):\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "Summarize the following conversation.\n",
        "\n",
        "{sample[\"dialogue\"]}\n",
        "\n",
        "Summary:\n",
        "\"\"\"\n",
        "        sample[\"input_ids\"] = tokenizer.encode(prompt, padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "\n",
        "        # This must be called \"query\", which is a requirement of PPO library.\n",
        "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
        "        return sample\n",
        "\n",
        "    for split in dataset.keys():\n",
        "        dataset[split] = dataset[split].map(tokenize)\n",
        "        dataset[split].set_format(type=\"torch\", columns=[\"input_ids\", \"query\"])\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "B5nrdg0XVFVt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484,
          "referenced_widgets": [
            "17c7755ba71a4054a22310f3d40f4553",
            "52b39d8b8ab44e4ab634dc9bdc45a827",
            "8df09b67c90d40e3bd14840592c6f82c",
            "c82b8b4dd9ad41d39b35bc6776bd26c8",
            "a11deed829f741dbbead64d05fc9a307",
            "3c6af176bab14de9ab382d52d10e78cc",
            "457f95bc94b3425fb52698b672a0d156",
            "d4ed4ce52d8d4571b2f8073cdf2e5ffc",
            "c1f951cbc7624a91a92d8e9a42e5fdef",
            "33aa3e0c85d845e9bd27e8ad5caf09ce",
            "ec363efc0ddf422c9cac40bd686f49ee",
            "f1b961f1c05f4117b7052de2bb6ab037",
            "be3a792eebc945d78739c8729d96b970",
            "06af961023de41e6a7250b74d9e701df",
            "531acbb0592948edb62f459e35531514",
            "760e6dcd7abe44378dcef28e084b8bc5",
            "535d2b578b574f23aaa35cfe94f5f071",
            "af010b626dae4a52a2e56042756b7593",
            "b6d712295df2413ab8ab7b14e14310cd",
            "67d8ab15897f4f62a7bfb5e033ab26b9",
            "63cdd1202cec4163ae52444bb6a4b213",
            "3f3a8054086a45ef9eea125b1eb61ae1",
            "4e95e7c177c14162a8982e12f29fcb15",
            "d01c9daa075741a589c5f35c162b032c",
            "ab3b5b786acc4a159060d6d9a90e36db",
            "68db1ba4773d443986ccc4a6ebd53930",
            "6dd76c9f010d4c3190dff3dbb098cfb9",
            "c65b0907eacd4264acf175d990bed246",
            "050487c7e9b1410c9e1de6f2d3be56bc",
            "59865656bd6d49f2ae862ad14daf7d74",
            "17d20198339b49f7aa53ebb3cc630cb8",
            "d1d2ebf2d9c8492ab76ea1640914bf2c",
            "18960c4c08024467b59ccba16b162182",
            "c20892dea2c340a0a5026ca3c75d7655",
            "f84661b35458468b8ef8be613902b939",
            "9e3bbf0eb46846349fc07e2141bf3766",
            "501cf00d29cd47c5becd320ff7b26d25",
            "f822a147c61b4213a1389e60354996b2",
            "08dc5d5acb9d4500858f5ff022335c69",
            "d31933a3a0174735a9f2bf01cc7f1091",
            "8b28f996e18b48eeae14bab57974b596",
            "e555ef9c6cb94c8cae586bff48d0a840",
            "12a7051fe48d47dcac28383e7f8d26af",
            "d337a89d93dc45ceb0f258b999219665",
            "acfeecff40e5402cab5f13addcc949ac",
            "233a27b97c304db1b031c347fc3ef105",
            "fe1b178134334cafbb297d8c8e6c1173",
            "51048122691e4a91a6b1896eda6f1b77",
            "7f181920e13a4b0ba946e5348521d560",
            "83d969a3af10414cbcf5247b10063064",
            "1d2928be758b45bb82cc4d17600a8703",
            "8b9a5362585c41fab757a29ee209f753",
            "21882dc1c62d4136a77096148686da96",
            "fa7f8199d52e411e840979d258f747d2",
            "c30d5da06709442d964c5b60d924c9f4",
            "b58797585fe84e70857743424073cd6e",
            "d004dd8234d9499cbec4f0020337fefd",
            "d1422c67d370431e9de70c554a9e2c71",
            "e75fd7b3f66345228eab34dd9ae624ae",
            "7232a4ec03b14917aebe783578f2abfd",
            "b5e83bee28114c2f8d7b99b82498ed96",
            "948e220bf9074026957b4ef4d9c90d90",
            "b3230c87eebe45b9a66795fff8fd766e",
            "32a2888e02ff4386bdcfa8a5ea5282d0",
            "e4fc7e2286de4efebad2d99f59e641d5",
            "f39c243ed3e24e0da1402ca98a85fd47",
            "9fd391a4dd3a4850837f62edb927f17c",
            "19f7b0a6751b415cb5fb2d8e49c63199",
            "89d5e5c2c1fc4cf9bc8243d271f5bc77",
            "c420394f2019471c8a425a1cd4acf128",
            "7732cfa7ca164b22936e58de3d06993e",
            "3e10d056346d447cb45ee2cff254dc6d",
            "4d83bdbd14fb43338b11bfca43cf5028",
            "4f005f9d791f4df199394db34633605f",
            "9dca7a4f801145eeb5337d2ec937ab42",
            "3f7aa942df944da6b11e10425f90e700",
            "3cf53b5387da40daa152bfe9d85a16dd"
          ]
        },
        "id": "B5nrdg0XVFVt",
        "outputId": "7fec9a01-fb67-4bbe-c966-6e3b03f9266b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4719825160a84232ba6f0af67c100733",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Map', max=500.0, style=ProgressStyle(description_width='i\u2026"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'query'],\n",
            "        num_rows: 12460\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'query'],\n",
            "        num_rows: 500\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'query'],\n",
            "        num_rows: 1500\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "dataset = build_dataset(model_path=model_path, dataset_path=dataset_path)\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([12198,  1635,  1737,     8,   826,  3634,     5,  1713,   345, 13515,\n",
            "          536,  4663,    10,  2018,     6,  1363,     5,  3931,     5,    27,\n",
            "           31,    51,  7582, 12833,    77,     7,     5,  1615,    33,    25,\n",
            "          270,   469,    58,  1713,   345, 13515,   357,  4663,    10,    27,\n",
            "          435,    34,   133,    36,     3,     9,   207,   800,    12,   129,\n",
            "            3,     9,   691,    18,   413,     5,  1713,   345, 13515,   536,\n",
            "         4663,    10,  2163,     6,   168,     6,    25,    43,    29,    31,\n",
            "           17,   141,    80,    21,   305,   203,     5,   148,   225,    43,\n",
            "           80,   334,   215,     5,  1713,   345, 13515,   357,  4663,    10,\n",
            "           27,   214,     5,    27,  2320,    38,   307,    38,   132,    19,\n",
            "         1327,  1786,     6,   572,   281,   217,     8,  2472,    58,  1713,\n",
            "          345, 13515,   536,  4663,    10,  1548,     6,     8,   200,   194,\n",
            "           12,  1792,  2261, 21154,    19,    12,   253,    91,    81,   135,\n",
            "          778,     5,   264,   653,    12,   369,    44,   709,   728,     3,\n",
            "            9,   215,    21,    39,   293,   207,     5,  1713,   345, 13515,\n",
            "          357,  4663,    10,  8872,     5,  1713,   345, 13515,   536,  4663,\n",
            "           10,  1563,   140,   217,   270,     5,   696,  2053,    11, 11581,\n",
            "          320,  1399,     5,  2321,     3,     9,  1659,  6522,     6,   754,\n",
            "            5,   531,    25,  7269,     6,  1363,     5,  3931,    58,  1713,\n",
            "          345, 13515,   357,  4663,    10,  2163,     5,  1713,   345, 13515,\n",
            "          536,  4663,    10, 14627,    53,    19,     8,  1374,  1137,    13,\n",
            "         5084,  1874,    11,   842,  1994,     6,    25,   214,     5,   148,\n",
            "          310,   225, 10399,     5,  1713,   345, 13515,   357,  4663,    10,\n",
            "           27,    31,   162,  1971,  3986,    13,   648,     6,    68,    27,\n",
            "          131,    54,    31,    17,  1727,    12,  4583,     8,  7386,     5,\n",
            "         1713,   345, 13515,   536,  4663,    10,  1548,     6,    62,    43,\n",
            "         2287,    11,   128, 11208,    24,   429,   199,     5,    27,    31,\n",
            "          195,   428,    25,    72,   251,   274,    25,  1175,     5,  1713,\n",
            "          345, 13515,   357,  4663,    10,  8872,     6,  2049,  2472,     5,\n",
            "        20698,    10,     3,     1,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Summarize the following conversation. #Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today? #Person2#: I found it would be a good idea to get a check-up. #Person1#: Yes, well, you haven't had one for 5 years. You should have one every year. #Person2#: I know. I figure as long as there is nothing wrong, why go see the doctor? #Person1#: Well, the best way to avoid serious illnesses is to find out about them early. So try to come at least once a year for your own good. #Person2#: Ok. #Person1#: Let me see here. Your eyes and ears look fine. Take a deep breath, please. Do you smoke, Mr. Smith? #Person2#: Yes. #Person1#: Smoking is the leading cause of lung cancer and heart disease, you know. You really should quit. #Person2#: I've tried hundreds of times, but I just can't seem to kick the habit. #Person1#: Well, we have classes and some medications that might help. I'll give you more information before you leave. #Person2#: Ok, thanks doctor. Summary: </s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
          ]
        }
      ],
      "source": [
        "sample = dataset[\"train\"][0]\n",
        "print(sample[\"input_ids\"])\n",
        "print(\"-\" * 100)\n",
        "print(sample[\"query\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7d03155e-649b-45bb-a5a0-94edd682c069",
      "metadata": {
        "id": "7d03155e-649b-45bb-a5a0-94edd682c069"
      },
      "source": [
        "Let's load the peft model trained in a GPU environment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21e06a57-fb80-4f8c-a967-4c7c42a7bfda",
      "metadata": {
        "id": "21e06a57-fb80-4f8c-a967-4c7c42a7bfda"
      },
      "source": [
        "Adding the fine-tuned adapter to the original FLAN-T5 model. In the fine tuning with peft phase, the fully trained adapter was added only for inferences, so there was no need to pass LoRA configurations doing that. Now there is need to pass them to the constructed PEFT model, also putting `is_trainable=True`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**The base model (e.g. flan-t5-base) + LoRA adapter = fine-tuned policy model.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "a1a94b14-b375-45e7-9e49-a7f2c341b4ff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "7b62effd7c454c6ba8e1b74efffed861",
            "ffc1ab23d039428da212c2441e3ed897",
            "ca70897208664c64a3385c18ee25bb74",
            "e2d2ea37e2ad455eb43d26d1885ab954",
            "01a0b344deaf4f41bdb264154b699b8d",
            "51879ef3f5f444a595b596fa74d90be4",
            "8e28548309a44579abf795fe4dfbd40d",
            "e47d59e408e84b6e8f2f994d81d69dda",
            "5b0af84b1b854985bf0367bf762295aa",
            "250dc51d1e8544089cee222fcba17906",
            "e7c4937a7eea480c86a8f21e0d09a17b",
            "ae07176423634008a448dc575888c5f9",
            "2247be7ffb1f434382a9311b857164d5",
            "6abe8773308c4e5e876adf3eac2c0dc5",
            "23810735b4d5494ca5e55cc71e122f1b",
            "d140b783fb7540d4a6b2039a49ad81c5",
            "1d5fa3301ae94bdf8aa40d29cc09a0b1",
            "a6d85a6b176b49df91d15136e322c33f",
            "8da69c34802c46348d34fee4f192a057",
            "2f888692fd3849c0a4d6cc1dbb08c6d3",
            "4d0847484bce4c969ef563433a111299",
            "aab7b982af4d4836949239898bb27b95",
            "34dcf7a12c524ff8a10c5cff6e31cc22",
            "e025772b52dc432fb8bec5446aab47b3",
            "073d378705e7467bab7a89f3748fe460",
            "b0684fa32f77489f974ed069ce23d259",
            "74e6085f4ce74c609fbd5b382ea417ad",
            "cb837c30e48b48fc9459ee30eb0ded14",
            "4cacfac2a4014445b714f7eaa0e856e2",
            "0b83600e3c1f4b598a41c03c2373349c",
            "9ea4b43f076247a4a9bcdcfbad0f6b24",
            "dc77b02a16d24067b98dc7abebf68119",
            "be344f9dc4d84e1ebfc518de7e5942fe"
          ]
        },
        "id": "a1a94b14-b375-45e7-9e49-a7f2c341b4ff",
        "outputId": "ceb22bff-5634-438e-e63b-f7401b17c259",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "lora_config = LoraConfig(\n",
        "    r=32,                            # Rank of the low-rank adaptation matrices\n",
        "    lora_alpha=32,                   # Scaling factor for LoRA weights\n",
        "    target_modules=[\"q\", \"v\"],       # Apply LoRA only to these modules (query, value in attention)\n",
        "    lora_dropout=0.05,               # Dropout applied to LoRA layers during training\n",
        "    bias=\"none\",                     # Whether to train bias terms\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM  # Task type: Sequence-to-Sequence Language Modeling\n",
        ")\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_path,\n",
        "                                              torch_dtype=torch.bfloat16).to(device)  # torch.bfloat16 to reduce memory\n",
        "\n",
        "peft_model = PeftModel.from_pretrained(model,\n",
        "                                       'peft_ft',    # fine-tuned LoRA adapter\n",
        "                                       lora_config=lora_config,\n",
        "                                       torch_dtype=torch.bfloat16,\n",
        "                                       device_map=device,\n",
        "                                       is_trainable=True)     # can update LoRA"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbd18d49",
      "metadata": {
        "id": "dbd18d49"
      },
      "source": [
        "pull out the number of model parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "d896ce26",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d896ce26",
        "outputId": "08abdbf5-f967-40c4-885d-5cd93d18cc17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total parameters: 251116800\n",
            "Trainable parameters: 3538944\n",
            "Trainable %: 1.41%\n"
          ]
        }
      ],
      "source": [
        "# total and trainable parameters\n",
        "total_params = sum(p.numel() for p in peft_model.parameters())\n",
        "trainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"Total parameters: {total_params}\")\n",
        "print(f\"Trainable parameters: {trainable_params}\")\n",
        "print(f\"Trainable %: {100 * trainable_params / total_params:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a950ae8a-76b9-4951-9c78-9ac7a6349e17",
      "metadata": {
        "id": "a950ae8a-76b9-4951-9c78-9ac7a6349e17"
      },
      "source": [
        "Preparing to fine-tune the LLM using Reinforcement Learning (RL). Preparing the Proximal Policy Optimization (PPO) model passing the instruct-fine-tuned PEFT model to it. PPO will be used to optimize the RL policy against the reward model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**A new value head used by PPO to estimate expected reward**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "1e86bab0-6dee-4dff-a754-b584ed962723",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e86bab0-6dee-4dff-a754-b584ed962723",
        "outputId": "c96a2dc5-5cf3-411e-aafa-dcdd8e7d475c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PPO model parameters to be updated (ValueHead + 769 params):\n",
            "\n",
            "Total parameters: 251117569\n",
            "Trainable parameters: 3539713\n",
            "Trainable %: 1.41%\n",
            "ValueHead(\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (summary): Linear(in_features=768, out_features=1, bias=True)\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "ppo_model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(peft_model,   # fine-tuned LoRA policy model\n",
        "                                                               torch_dtype=torch.bfloat16,\n",
        "                                                               is_trainable=True).to(device) # PPO can update LoRA + value head\n",
        "\n",
        "print(f'PPO model parameters to be updated (ValueHead + 769 params):\\n')\n",
        "# total and trainable parameters\n",
        "total_params = sum(p.numel() for p in ppo_model.parameters())\n",
        "trainable_params = sum(p.numel() for p in ppo_model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"Total parameters: {total_params}\")\n",
        "print(f\"Trainable parameters: {trainable_params}\")\n",
        "print(f\"Trainable %: {100 * trainable_params / total_params:.2f}%\")\n",
        "print(ppo_model.v_head)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c4ec7eb",
      "metadata": {
        "id": "7c4ec7eb"
      },
      "source": [
        "During PPO, only a few parameters will be updated. Specifically, the parameters of the `ValueHead`. More information about this class of models can be found in the [documentation](https://huggingface.co/docs/trl/main/en/models#trl.create_reference_model). The number of trainable parameters computed as $(n+1)*m$, where $n$ is the number of input units (here $n=768$) and $m$ is the number of output units (you have $m=1$). The $+1$ term in the equation takes into account the bias term."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "25afde42",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25afde42",
        "outputId": "6273b1ba-46d4-4beb-dc8e-ce90f74ea83b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3539713"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "3538944 + 769 # Trainable"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76c7e2df-0c75-4bd0-bf8d-1f1545ef864e",
      "metadata": {
        "id": "76c7e2df-0c75-4bd0-bf8d-1f1545ef864e"
      },
      "source": [
        "Creating a frozen copy of the PPO which will not be fine-tuned - a reference model. The reference model will represent the LLM before detoxification. None of the parameters of the reference model will be updated during PPO training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In PPO (Proximal Policy Optimization) with RLHF, we need two models:\n",
        "\n",
        "- ppo_model \u2013 the policy model WE're training (LoRA + value head)\n",
        "- ref_model \u2013 the reference model used to compute the KL divergence (a penalty if the new model strays too far from the original)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "18a9b30a-ad14-4189-8088-d4de447fe247",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18a9b30a-ad14-4189-8088-d4de447fe247",
        "outputId": "89af409a-0588-4589-f44e-cff09900d10b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total parameters: 251117569\n",
            "Trainable parameters: 0\n",
            "Trainable %: 0.00%\n"
          ]
        }
      ],
      "source": [
        "ref_model = create_reference_model(ppo_model)\n",
        "\n",
        "total_params = sum(p.numel() for p in ref_model.parameters())\n",
        "trainable_params = sum(p.numel() for p in ref_model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"Total parameters: {total_params}\")\n",
        "print(f\"Trainable parameters: {trainable_params}\")\n",
        "print(f\"Trainable %: {100 * trainable_params / total_params:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3a14848-e83d-4fdd-bc68-eb770c5951d7",
      "metadata": {
        "id": "e3a14848-e83d-4fdd-bc68-eb770c5951d7"
      },
      "source": [
        "Everything is set. It is time to prepare the reward model!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bfdf1f7-3509-4adc-812a-2b22bd330137",
      "metadata": {
        "id": "4bfdf1f7-3509-4adc-812a-2b22bd330137"
      },
      "source": [
        "### Prepare Reward Model\n",
        "\n",
        "**Reinforcement Learning (RL)** is one type of machine learning where agents take actions in an environment aimed at maximizing their cumulative rewards. The agent's behavior is defined by the **policy**. And the goal of reinforcement learning is for the agent to learn an optimal, or nearly-optimal, policy that maximizes the **reward function**.\n",
        "\n",
        "The original policy is based on the instruct PEFT model - this is the LLM before detoxification and it was trained on dialogue summaries dataset in a GPU environment. We ask human labelers to give feedback on the outputs' toxicity. However, it can be expensive to use them for the entire fine-tuning process. A practical way to avoid that is to use a reward model encouraging the agent to detoxify the dialogue summaries. The intuitive approach would be to do some form of sentiment analysis across two classes (`nothate` and `hate`) and give a higher reward if there is higher a chance of getting class `nothate` as an output."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7d0c312",
      "metadata": {
        "id": "c7d0c312"
      },
      "source": [
        "Having human labelers for the entire finetuning process can be expensive. A practical way to avoid that is to use a reward model.\n",
        "Use feedback generated by a model\n",
        "\n",
        "We will use [Meta AI's RoBERTa-based hate speech model](https://huggingface.co/facebook/roberta-hate-speech-dynabench-r4-target) for the reward model. This model will output **logits** and then predict probabilities across two classes: `nothate` and `hate`. The logits of the output `nothate` will be taken as a positive reward. Then, the model will be fine-tuned with PPO using those reward values.\n",
        "\n",
        "Creating the instance of the required model class for the RoBERTa model. Loading a tokenizer to test the model. The model label `0` will correspond to the class `nothate` and label `1` to the class `hate`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Purpose: For every generated summary, this model gives a score. The score for \"nothate\" is our reward signal.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "id": "7f038a9f-e04b-49bc-8923-8ef3816919ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226,
          "referenced_widgets": [
            "c58979a23674402c8038bcc23ebf8cd6",
            "3089bb27190049fca717ec8c96e65ace",
            "c1e22f8cffd14ac8830424ed5f55e92f",
            "0b27236daf4a44da85b442c02dbd3067",
            "16f9dea7b805454c89b51c1e73b02cd0",
            "bf607ce5c8a54defabf3b46b64192e37",
            "cb8d8552bbc34b67ac2b2a113c1b4cbc",
            "0abe74594e194e779552ff50f4ba78c7",
            "23588b1c97cc43cbac380b8834f16526",
            "efef88fda2fe48e3bc310cc41c47f9c0",
            "282fe1db12374d91a7dca8038b171701",
            "a62df0bd9c92439eae916d870b454f39",
            "bc3d148ee68a4de58087a560b8356f12",
            "f61510fcd7524efebab8c07caf9a95d5",
            "9138647e20214014b54f84aa49ac5a71",
            "1b1d7eb31bfb491e8642c79a966ec4d7",
            "e9e64e73760c40a8ba757ae84af9d155",
            "0642cad3c7774b03b070250f764e21ee",
            "916bdfbe1a7e4bbf97b703da7f5db658",
            "d5b916380cc4452792d1f44a9f24731b",
            "79ecabba09164cf8bdd9c125c988006d",
            "1f559e177e7440189a607a93ad9e4172",
            "59566440ed184df6a6bbedaca7179320",
            "2e666ecc50e04c6c90da667260428e45",
            "84b63fe19dc74fe68d35938c2a8040d5",
            "d2baf84fc5844817a337f9f9557a9fb0",
            "221e74b33d434454a024e05732ea7c30",
            "568f30643be849d78a2664525234064b",
            "926f72f0699b49a19c2c49ae23023e2e",
            "e6752aea6a124ff48de3dfccc1289f75",
            "f87499c873cd4548ae868932e6c9887d",
            "db7b7e040f5b47a6906bdd7665d4a5ed",
            "0e10c8301a0846028d5dd899130f940d",
            "a58f125acdbc4c53b6d38ef65dcfa913",
            "d176d6428c814e6b86b994c3f6a4cbad",
            "bc8f6b6ee408462195c7126cdfe06cdf",
            "51cd810a52e546b683f97c773a9527f1",
            "b7e8efa85c754a439b9920bad1d4019e",
            "dc9f729848dc40c2844d5f025297d145",
            "de7c9484ba0843808a33690da9bcebb2",
            "43791eb9cc464f5a92bcbb19ff702bea",
            "47ae16dbd4de4af390d06a38b5d22ac1",
            "801a36f443bd470e8d0f4a7e4f6b2ddb",
            "8fb13629068b480785e432a73e2a3e55",
            "2bbf0556b60b4312957c538a276eb21a",
            "66a6fdbe01e54ebfbfb7618d4d3443e7",
            "a75ceb5dfb114a2cb381fe3f7bda6a62",
            "c5d557d6f6e44137a5238250cc5e6dc9",
            "e3db8e6c2ce0477092c1431edac63ff3",
            "4064962248cd4d67b13acaf4884f2cef",
            "0e2f5855e96d403198870df5f1fe1f97",
            "ff7a7906e93e423c946a6b498dc22cfc",
            "37bc4969567f4d4e9a7ef82f80410bcc",
            "a59186ebcce4412bbfb552f074de403b",
            "cd708a746ac642938be0a75b1cd2c73e",
            "6b2426fba0d94717b4ce774c669cf16b",
            "9e1192b4e21e42c78724824050da8512",
            "31cc4a945f5b427abddeda0da7ad6b04",
            "993ebabee7434c0aad0ed3f56ff1cc2b",
            "1ed6856d2e4d4824bb837e248ef26e7c",
            "2381a94547e64d329b2fc6e85a899b47",
            "a60487b9cc8a41cebb7b0cd6f393c9ef",
            "58eace12bc28454cb45058bedec5446e",
            "ee734169755a4b72941625ecdea6c7ee",
            "78827564acab4f5dac6fbb812c29a18a",
            "780325c240374349811fcd36a0d3065d"
          ]
        },
        "id": "7f038a9f-e04b-49bc-8923-8ef3816919ee",
        "outputId": "17d0018d-9cc8-4801-fdca-6eca5bf5fbf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'nothate', 1: 'hate'}\n"
          ]
        }
      ],
      "source": [
        "toxicity_model_name = \"toxicity-roberta/\"\n",
        "toxicity_tokenizer = AutoTokenizer.from_pretrained(toxicity_model_name, device_map=device)\n",
        "toxicity_model = AutoModelForSequenceClassification.from_pretrained(toxicity_model_name, device_map=device)\n",
        "print(toxicity_model.config.id2label)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79d68799-a6e8-42d7-8d61-002e47210c18",
      "metadata": {
        "id": "79d68799-a6e8-42d7-8d61-002e47210c18"
      },
      "source": [
        "Taking some non-toxic text, tokenize it, and pass it to the model. Printing the output logits, probabilities, and the corresponding reward that will be used for fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [],
      "source": [
        "not_hate_index = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "id": "8f4e6a05-2398-4ca7-a176-d5a1ff27fe39",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f4e6a05-2398-4ca7-a176-d5a1ff27fe39",
        "outputId": "d95e7132-2929-4437-b285-2fc24780ac00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "logits [not hate, hate]: [3.114103078842163, -2.4896199703216553]\n",
            "probabilities [not hate, hate]: [0.9963293671607971, 0.003670599078759551]\n",
            "reward (high): [3.114103078842163]\n"
          ]
        }
      ],
      "source": [
        "non_toxic_text = \"#Person 1# tells Tommy that he didn't like the movie.\"\n",
        "toxicity_input_ids = toxicity_tokenizer(non_toxic_text, return_tensors=\"pt\").input_ids\n",
        "toxicity_input_ids = toxicity_input_ids.to(device)\n",
        "\n",
        "logits = toxicity_model(input_ids=toxicity_input_ids).logits\n",
        "print(f'logits [not hate, hate]: {logits.tolist()[0]}')\n",
        "\n",
        "# Print the probabilities for [not hate, hate]\n",
        "probabilities = logits.softmax(dim=-1).tolist()[0]\n",
        "print(f'probabilities [not hate, hate]: {probabilities}')\n",
        "\n",
        "# get the logits for \"not hate\" - this is the reward!\n",
        "nothate_reward = (logits[:, not_hate_index]).tolist()\n",
        "print(f'reward (high): {nothate_reward}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63f729c5-98c3-4745-96e8-3484670215db",
      "metadata": {
        "id": "63f729c5-98c3-4745-96e8-3484670215db"
      },
      "source": [
        "Let's show a toxic comment.  This will have a low reward because it is more toxic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "id": "0ffc81e4-b220-4f4e-95ec-98ac418612d1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ffc81e4-b220-4f4e-95ec-98ac418612d1",
        "outputId": "1337c2b0-a5ae-45cd-d4db-ab825382d432"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "logits [not hate, hate]: [-0.6921160817146301, 0.3722703754901886]\n",
            "probabilities [not hate, hate]: [0.25647208094596863, 0.743527889251709]\n",
            "reward (low): [-0.6921160817146301]\n"
          ]
        }
      ],
      "source": [
        "toxic_text = \"#Person 1# tells Tommy that the movie was terrible, dumb and stupid.\"\n",
        "toxicity_input_ids = toxicity_tokenizer(toxic_text, return_tensors=\"pt\").input_ids\n",
        "toxicity_input_ids = toxicity_input_ids.to(device)\n",
        "\n",
        "logits = toxicity_model(toxicity_input_ids).logits\n",
        "print(f'logits [not hate, hate]: {logits.tolist()[0]}')\n",
        "\n",
        "# Print the probabilities for [not hate, hate]\n",
        "probabilities = logits.softmax(dim=-1).tolist()[0]\n",
        "print(f'probabilities [not hate, hate]: {probabilities}')\n",
        "\n",
        "# Get the logits for \"not hate\" - this is the reward!\n",
        "nothate_reward = (logits[:, not_hate_index]).tolist()\n",
        "print(f'reward (low): {nothate_reward}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4290f36",
      "metadata": {
        "id": "f4290f36"
      },
      "source": [
        "How This Fits into Phase 3 (PPO)\n",
        "In the final RLHF phase, the PPO trainer will:\n",
        "\n",
        "- Use SFT model (peft ft) to generate a summary.\n",
        "\n",
        "- Feed that summary to this toxicity_model to get a reward.\n",
        "\n",
        "- Update SFT model to teach it to generate summaries that get a high score from the toxicity judge.\n",
        "\n",
        "The end result will be a summarization model that is actively optimized to avoid producing toxic content."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc6e656e-fefe-4623-8bbb-472a8cf1c3c5",
      "metadata": {
        "id": "bc6e656e-fefe-4623-8bbb-472a8cf1c3c5"
      },
      "source": [
        "Setup Hugging Face inference pipeline to simplify the code for the toxicity reward model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "id": "73aab8c6-33eb-4bf4-a816-3866fc3460af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73aab8c6-33eb-4bf4-a816-3866fc3460af",
        "outputId": "2227ae62-d690-43f7-ebc3-ad22e78e86b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reward model output:\n",
            "For non-toxic text\n",
            "[{'label': 'nothate', 'score': 3.114103078842163}, {'label': 'hate', 'score': -2.4896199703216553}]\n",
            "[{'label': 'nothate', 'score': 0.9963293671607971}, {'label': 'hate', 'score': 0.0036705993115901947}]\n",
            "For toxic text\n",
            "[{'label': 'hate', 'score': 0.3722703754901886}, {'label': 'nothate', 'score': -0.6921160817146301}]\n",
            "[{'label': 'hate', 'score': 0.743527889251709}, {'label': 'nothate', 'score': 0.25647208094596863}]\n"
          ]
        }
      ],
      "source": [
        "sentiment_pipe = pipeline(\"sentiment-analysis\",\n",
        "                          model=toxicity_model_name,\n",
        "                          device=device,\n",
        "                          framework=\"pt\")\n",
        "\n",
        "reward_logits_kwargs = {\n",
        "    \"top_k\": None,                  # Return all scores.\n",
        "    \"function_to_apply\": \"none\",    # Set to \"none\" to retrieve raw logits.\n",
        "    \"batch_size\": 16\n",
        "}\n",
        "\n",
        "reward_probabilities_kwargs = {\n",
        "    \"top_k\": None,                  # Return all scores.\n",
        "    \"function_to_apply\": \"softmax\", # Set to \"softmax\" to apply softmax and retrieve probabilities.\n",
        "    \"batch_size\": 16\n",
        "}\n",
        "\n",
        "print(\"Reward model output:\")\n",
        "print(\"For non-toxic text\")\n",
        "print(sentiment_pipe(non_toxic_text, **reward_logits_kwargs))\n",
        "print(sentiment_pipe(non_toxic_text, **reward_probabilities_kwargs))\n",
        "print(\"For toxic text\")\n",
        "print(sentiment_pipe(toxic_text, **reward_logits_kwargs))\n",
        "print(sentiment_pipe(toxic_text, **reward_probabilities_kwargs))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21302d74-59d8-451f-b287-e86245bf3324",
      "metadata": {
        "id": "21302d74-59d8-451f-b287-e86245bf3324"
      },
      "source": [
        "The outputs are the logits for both `nothate` (positive) and `hate` (negative) classes. But PPO will be using logits only of the `nothate` class as the positive reward signal used to help detoxify the LLM outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "id": "36ff3925-70c4-495c-ae26-68e2fc36296b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36ff3925-70c4-495c-ae26-68e2fc36296b",
        "outputId": "616941ef-dfca-430d-c1c7-00c80f4ed872"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'label': 'nothate', 'score': 3.114103078842163}, {'label': 'hate', 'score': -2.4896199703216553}]\n",
            "[{'label': 'nothate', 'score': 0.9963293671607971}, {'label': 'hate', 'score': 0.0036705993115901947}]\n"
          ]
        }
      ],
      "source": [
        "print(sentiment_pipe(non_toxic_text, **reward_logits_kwargs))\n",
        "print(sentiment_pipe(non_toxic_text, **reward_probabilities_kwargs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "id": "8d11618b-5887-489a-b390-2139e364987f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d11618b-5887-489a-b390-2139e364987f",
        "outputId": "542833be-f0b6-493d-c4c4-c1d3846244b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'label': 'hate', 'score': 0.3722703754901886}, {'label': 'nothate', 'score': -0.6921160817146301}]\n",
            "[{'label': 'hate', 'score': 0.743527889251709}, {'label': 'nothate', 'score': 0.25647208094596863}]\n"
          ]
        }
      ],
      "source": [
        "print(sentiment_pipe(toxic_text, **reward_logits_kwargs))\n",
        "print(sentiment_pipe(toxic_text, **reward_probabilities_kwargs))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56513033-9bb1-41d5-81e2-54d1249c5c89",
      "metadata": {
        "id": "56513033-9bb1-41d5-81e2-54d1249c5c89"
      },
      "source": [
        "### Evaluate Toxicity\n",
        "\n",
        "To evaluate the model before and after fine-tuning/detoxification, Setting up the [toxicity evaluation metric](https://huggingface.co/spaces/evaluate-measurement/toxicity). The **toxicity score** is a decimal value between 0 and 1 where 1 is the highest toxicity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.003670599078759551]\n",
            "[0.743527889251709]\n"
          ]
        }
      ],
      "source": [
        "def get_toxicity_score(texts):\n",
        "    if isinstance(texts, str):\n",
        "        texts = [texts]\n",
        "    inputs = toxicity_tokenizer(texts, return_tensors=\"pt\", truncation=True, padding=True).to(toxicity_model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = toxicity_model(**inputs)\n",
        "        scores = torch.softmax(outputs.logits, dim=-1)\n",
        "    return scores[:, 1].tolist()  # Return list of \"hate\" class scores\n",
        "\n",
        "\n",
        "print(get_toxicity_score(non_toxic_text))\n",
        "print(get_toxicity_score(toxic_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "7de8e99d-60ea-48a2-bdf5-817f80b48979",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "ddf03cba5e434fccaca1a31ae134031a",
            "670a7e81deab41a1a16add3ea1717a4b",
            "6456c18175e540cca029e575a5cf28c5",
            "6f78b9193d044928b6e062cb08680bd6",
            "e68ecc15f82f45d2920dae81e1826ca1",
            "d1598d3eed424dbd8444f8cf432748b1",
            "f53ba4ba1a3446b1bff44bdefe5c1cdf",
            "c52b2d593dc74c8983c949062a8c2a39",
            "0a7fd6dd0bc24872a1759b6256932cc4",
            "c800139caaa74fc48eb979fafd63afa0",
            "6e1bff80625d47fc846bb8aa6ee5a95f"
          ]
        },
        "id": "7de8e99d-60ea-48a2-bdf5-817f80b48979",
        "outputId": "c5af049f-8ccd-4d30-d078-7503d877a6c6"
      },
      "outputs": [],
      "source": [
        "# toxicity_evaluator = evaluate.load(\"toxicity\",\n",
        "#                                     'facebook/roberta-hate-speech-dynabench-r4-target',\n",
        "#                                     module_type=\"measurement\",\n",
        "#                                     toxic_label=\"hate\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "840fbc47-c5c2-469a-b5f2-6407e8f0bfde",
      "metadata": {
        "id": "840fbc47-c5c2-469a-b5f2-6407e8f0bfde"
      },
      "source": [
        "Calculating toxicity for the same sentences. Toxicity scores are the probabilities of `hate` class returned directly from the reward model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "5298f91c-30d1-4d17-95a7-553952ac97b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5298f91c-30d1-4d17-95a7-553952ac97b5",
        "outputId": "769e901f-4503-4861-9791-26eed0d96451"
      },
      "outputs": [],
      "source": [
        "# toxicity_score = toxicity_evaluator.compute(predictions=[\n",
        "#     non_toxic_text\n",
        "# ])\n",
        "# print(\"Toxicity score for non-toxic text:\")\n",
        "# print(toxicity_score[\"toxicity\"])\n",
        "\n",
        "# toxicity_score = toxicity_evaluator.compute(predictions=[\n",
        "#     toxic_text\n",
        "# ])\n",
        "# print(\"\\nToxicity score for toxic text:\")\n",
        "# print(toxicity_score[\"toxicity\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d3e835b-14b9-4646-b1c9-c975ef3ea944",
      "metadata": {
        "id": "7d3e835b-14b9-4646-b1c9-c975ef3ea944"
      },
      "source": [
        "This evaluator can be used to compute the toxicity of the dialogues. Need to pass the test dataset (`dataset[\"test\"]`), the same tokenizer which was used before, the frozen PEFT model prepared before, and the toxicity evaluator. It is convenient to wrap the required steps in the function `evaluate_toxicity`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "id": "316ab128-33ff-4a1e-8936-47bfa29d48a3",
      "metadata": {
        "id": "316ab128-33ff-4a1e-8936-47bfa29d48a3"
      },
      "outputs": [],
      "source": [
        "def evaluate_toxicity(model,\n",
        "                      toxicity_evaluator,\n",
        "                      tokenizer,\n",
        "                      dataset,\n",
        "                      num_samples):\n",
        "\n",
        "    \"\"\"\n",
        "    Evaluate the toxicity of the model.\n",
        "\n",
        "    Parameters:\n",
        "    - model (trl model): Model to be evaluated.\n",
        "    - toxicity_evaluator (evaluate_modules toxicity metrics): Toxicity evaluator.\n",
        "    - tokenizer (transformers tokenizer): Tokenizer to be used.\n",
        "    - dataset (dataset): Input dataset for the evaluation.\n",
        "    - num_samples (int): Maximum number of samples for the evaluation.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing two numpy.float64 values:\n",
        "    - mean (numpy.float64): Mean of the samples toxicity.\n",
        "    - std (numpy.float64): Standard deviation of the samples toxicity.\n",
        "    \"\"\"\n",
        "\n",
        "    max_new_tokens=100\n",
        "\n",
        "    toxicities = []\n",
        "    input_texts = []\n",
        "    for i, sample in tqdm(enumerate(dataset)):\n",
        "        input_text = sample[\"query\"]\n",
        "\n",
        "        if i > num_samples:\n",
        "            break\n",
        "\n",
        "        input_ids = tokenizer(input_text, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\").input_ids\n",
        "        input_ids = input_ids.to(device)\n",
        "\n",
        "        generation_config = GenerationConfig(max_new_tokens=max_new_tokens,\n",
        "                                             top_k=0.0,\n",
        "                                             top_p=1.0,\n",
        "                                             do_sample=True)\n",
        "\n",
        "        response_token_ids = model.generate(input_ids=input_ids,\n",
        "                                            generation_config=generation_config)\n",
        "\n",
        "        generated_text = tokenizer.decode(response_token_ids[0], skip_special_tokens=True)\n",
        "\n",
        "        toxicity_score = toxicity_evaluator([input_text + \" \" + generated_text])\n",
        "\n",
        "        toxicities.append(toxicity_score)\n",
        "\n",
        "    # Compute mean & std using np.\n",
        "#     print(toxicities)\n",
        "    mean = np.mean(toxicities)\n",
        "    std = np.std(toxicities)\n",
        "\n",
        "    return mean, std"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aed269c3-dbd7-4d45-bc44-c6ab6d4ae141",
      "metadata": {
        "id": "aed269c3-dbd7-4d45-bc44-c6ab6d4ae141"
      },
      "source": [
        "Performing the calculation of the model toxicity before fine-tuning/detoxification:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "c11ede15-dc1a-4a7e-a60d-b9cadfc7d876",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c11ede15-dc1a-4a7e-a60d-b9cadfc7d876",
        "outputId": "38ebbf80-8ca0-4cc8-8a0d-f5df70f825a1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "51it [00:59,  1.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "toxicity [mean, std] before detox: [0.155942528782522, 0.061500386888910345]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_path, device_map=device)\n",
        "\n",
        "mean_before_detoxification, std_before_detoxification = evaluate_toxicity(model=ref_model,\n",
        "                                                                          toxicity_evaluator=get_toxicity_score,\n",
        "                                                                          tokenizer=tokenizer,\n",
        "                                                                          dataset=dataset[\"test\"],\n",
        "                                                                          num_samples=50)\n",
        "\n",
        "print(f'toxicity [mean, std] before detox: [{mean_before_detoxification}, {std_before_detoxification}]')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ba81c90-1ac8-4403-ac1a-d4c75c6df4f0",
      "metadata": {
        "id": "1ba81c90-1ac8-4403-ac1a-d4c75c6df4f0"
      },
      "source": [
        "## Performing Fine-Tuning to Detoxify the Summaries\n",
        "Optimizing a RL policy against the reward model using Proximal Policy Optimization (PPO)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5516e318-8fce-4ca7-bf19-b7baf5255480",
      "metadata": {
        "id": "5516e318-8fce-4ca7-bf19-b7baf5255480"
      },
      "source": [
        "### Initialize `PPOTrainer`\n",
        "\n",
        "For the `PPOTrainer` initialization, we will need a collator. Here it will be a function transforming the dictionaries in a particular way. We can define and test it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "8b7be1c0-382a-4fe2-8174-470f3e333e84",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b7be1c0-382a-4fe2-8174-470f3e333e84",
        "outputId": "3c447111-6ff4-4a36-a8d5-0155a710d7b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collator input: [{'key1': 'value1', 'key2': 'value2', 'key3': 'value3'}]\n",
            "Collator output: {'key1': ['value1'], 'key2': ['value2'], 'key3': ['value3']}\n"
          ]
        }
      ],
      "source": [
        "def collator(data):\n",
        "    return dict((key, [d[key] for d in data]) for key in data[0])\n",
        "\n",
        "test_data = [{\"key1\": \"value1\", \"key2\": \"value2\", \"key3\": \"value3\"}]\n",
        "print(f'Collator input: {test_data}')\n",
        "print(f'Collator output: {collator(test_data)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "080c2e92-4988-4944-8353-0e1bb2048072",
      "metadata": {
        "id": "080c2e92-4988-4944-8353-0e1bb2048072"
      },
      "source": [
        "Setting up the configuration parameters. Loading the `ppo_model` and the tokenizer. We will also load a frozen version of the model `ref_model`. The first model is optimized while the second model serves as a reference to calculate the KL-divergence from the starting point. This works as an additional reward signal in the PPO training to make sure the optimized model does not deviate too much from the original LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "494e09a1-9024-4f38-91eb-d73cdc3239e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "494e09a1-9024-4f38-91eb-d73cdc3239e6",
        "outputId": "062bb43d-ab94-48d0-aa60-a3378bc8b271"
      },
      "outputs": [],
      "source": [
        "learning_rate=1.41e-5\n",
        "max_ppo_epochs=1\n",
        "mini_batch_size=4\n",
        "batch_size=16\n",
        "\n",
        "config = PPOConfig(\n",
        "    model_name=model_path,    # for logging\n",
        "    learning_rate=learning_rate,\n",
        "    ppo_epochs=max_ppo_epochs,\n",
        "    mini_batch_size=mini_batch_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "ppo_trainer = PPOTrainer(config=config,\n",
        "                         model=ppo_model,     # model that will generate summaries and be updated.\n",
        "                         ref_model=ref_model,\n",
        "                         tokenizer=tokenizer,\n",
        "                         dataset=dataset[\"train\"],\n",
        "                         data_collator=collator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/778 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Batch 1 -----------------------------\n",
            "input_ids:\n",
            "  Type: <class 'list'>\n",
            "  Length: 16\n",
            "  Sample: tensor([12198,  1635,  1737,     8,   826,  3634,     5,  1713,   345, 13515,\n",
            "          536,  4663,    10,  1804,  1379,     6,   283,  5805,  1589,     5,\n",
            "         1713,   345, 13515,   357,  4663,    10,  1804,  1379,     5,  9348,\n",
            "           25,   199,   140,   754,    58,    27,    31,    51,   479,    21,\n",
            "          128,  1335,    21,    82,  2039,     5,  1713,   345, 13515,   536,\n",
            "         4663,    10,  6902,     5,   363,   773,    13,  1335,    19,   255,\n",
            "         1638,    16,    58,  1713,   345, 13515,   357,  4663,    10,   451,\n",
            "           31,     7,   182,  3036,    13,  7966,   333,  1937,     5,  1713,\n",
            "          345, 13515,   536,  4663,    10,    27,   217,     5,   363,    81,\n",
            "           48,    80,    58,  4498,   255,   608,    34,   274,    58,  1713,\n",
            "          345, 13515,   357,  4663,    10,    27,    31,    51,    59,   417,\n",
            "            5,   299,   255,  1077,   751,    31,    17,  1423,     8,   733,\n",
            "          237,     3,    99,   255,    65,     5,   451,    31,     7,   182,\n",
            "         2612,  1329,     5,  1713,   345, 13515,   536,  4663,    10,   571,\n",
            "          625,    19,   255,    58,  1713,   345, 13515,   357,  4663,    10,\n",
            "          451,    31,   195,    36,  2777,   416,   215,     5,  1713,   345,\n",
            "        13515,   536,  4663,    10,   465,  3337,    55,  5264,    12, 18486,\n",
            "           34,     3,    99,   255,    54,    31,    17,  1992,  1183,    34,\n",
            "          441,   985,     3,     9,   847,     5,  1713,   345, 13515,   357,\n",
            "         4663,    10,  2163,     6,    27,    56,     5,  1562,    25,   182,\n",
            "          231,     5,  1713,   345, 13515,   536,  4663,    10,   148,    33,\n",
            "         2222,     5, 20698,    10,     3,     1,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0], device='cuda:0')\n",
            "query:\n",
            "  Type: <class 'list'>\n",
            "  Length: 16\n",
            "  Sample: Summarize the following conversation. #Person1#: Good morning, Mister Black. #Person2#: Good morning. Could you help me please? I'm looking for some books for my mother. #Person1#: OK. What kind of books is she interested in? #Person2#: She's very fond of romantic love stories. #Person1#: I see. What about this one? Has she read it before? #Person2#: I'm not sure. But she probably won't remember the story even if she has. She's very forgetful. #Person1#: How old is she? #Person2#: She'll be 90 next year. #Person1#: No wonder! Remember to renew it if she can't finish reading it within half a month. #Person2#: Yes, I will. Thank you very much. #Person1#: You are welcome. Summary: </s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Just check first few batches to avoid printing everything\n",
        "for i, batch in enumerate(tqdm(ppo_trainer.dataloader)):\n",
        "    print(f\"\\nBatch {i+1} -----------------------------\")\n",
        "    for key, value in batch.items():\n",
        "        print(f\"{key}:\")\n",
        "        print(f\"  Type: {type(value)}\")\n",
        "        print(f\"  Length: {len(value)}\")\n",
        "        print(f\"  Sample: {value[0] if len(value) > 0 else 'Empty'}\")\n",
        "    \n",
        "    if i >= 0:  # Print only first 1 batches\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ad77d2c-3800-4e15-bb38-3851d94ad374",
      "metadata": {
        "id": "7ad77d2c-3800-4e15-bb38-3851d94ad374"
      },
      "source": [
        "### Fine-Tuning the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cac21fb-fea5-4e80-a741-87f35ae72c62",
      "metadata": {
        "id": "0cac21fb-fea5-4e80-a741-87f35ae72c62"
      },
      "source": [
        "The fine-tuning loop consists of the following main steps:\n",
        "1. Get the query responses from the policy LLM (PEFT model).\n",
        "2. Get sentiments for query/responses from hate speech RoBERTa model.\n",
        "3. Optimize policy with PPO using the (query, response, reward) triplet.\n",
        "\n",
        "The operation is running if we see the following metrics appearing:\n",
        "* `objective/kl`: minimize kl divergence,\n",
        "* `ppo/returns/mean`: maximize mean returns,\n",
        "* `ppo/policy/advantages_mean`: maximize advantages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1it [00:22, 22.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 29.8692569732666\n",
            "ppo/returns/mean: -0.7105279564857483\n",
            "ppo/policy/advantages_mean: 0.03865646570920944\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2it [00:45, 22.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 27.942033767700195\n",
            "ppo/returns/mean: -0.5913649797439575\n",
            "ppo/policy/advantages_mean: -0.01949869468808174\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "3it [01:08, 22.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 23.8763427734375\n",
            "ppo/returns/mean: -0.40408796072006226\n",
            "ppo/policy/advantages_mean: 0.019763007760047913\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "4it [01:30, 22.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 24.580785751342773\n",
            "ppo/returns/mean: -0.4259708523750305\n",
            "ppo/policy/advantages_mean: 0.008730333298444748\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5it [01:50, 21.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 25.407394409179688\n",
            "ppo/returns/mean: -0.667657196521759\n",
            "ppo/policy/advantages_mean: 0.009261667728424072\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "6it [02:11, 21.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 29.2171688079834\n",
            "ppo/returns/mean: -0.7416467070579529\n",
            "ppo/policy/advantages_mean: 0.03365052118897438\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7it [02:36, 22.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 31.408376693725586\n",
            "ppo/returns/mean: -0.7978940010070801\n",
            "ppo/policy/advantages_mean: 0.006953757256269455\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "8it [02:57, 22.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 28.310871124267578\n",
            "ppo/returns/mean: -0.7717138528823853\n",
            "ppo/policy/advantages_mean: 0.0033638998866081238\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "9it [03:18, 21.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 28.54660415649414\n",
            "ppo/returns/mean: -0.7099393606185913\n",
            "ppo/policy/advantages_mean: 0.03477070480585098\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10it [03:38, 21.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 26.7115478515625\n",
            "ppo/returns/mean: -0.6599987745285034\n",
            "ppo/policy/advantages_mean: -0.008014802820980549\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "11it [04:04, 22.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 26.15050506591797\n",
            "ppo/returns/mean: -0.4622223973274231\n",
            "ppo/policy/advantages_mean: 0.06417703628540039\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12it [04:25, 22.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 29.36651611328125\n",
            "ppo/returns/mean: -0.7187207341194153\n",
            "ppo/policy/advantages_mean: 0.023820359259843826\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "13it [04:47, 22.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 29.664627075195312\n",
            "ppo/returns/mean: -0.7477931976318359\n",
            "ppo/policy/advantages_mean: 0.07534753531217575\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "14it [05:09, 22.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 33.3677864074707\n",
            "ppo/returns/mean: -0.8446346521377563\n",
            "ppo/policy/advantages_mean: 0.0002432204782962799\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15it [05:29, 21.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 26.80718231201172\n",
            "ppo/returns/mean: -0.6729015707969666\n",
            "ppo/policy/advantages_mean: -0.006134204566478729\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "16it [05:49, 21.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 30.157691955566406\n",
            "ppo/returns/mean: -0.7592501044273376\n",
            "ppo/policy/advantages_mean: 0.028080806136131287\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "17it [06:14, 22.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 32.847564697265625\n",
            "ppo/returns/mean: -0.803838849067688\n",
            "ppo/policy/advantages_mean: 0.006235269829630852\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "18it [06:35, 21.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 28.92570686340332\n",
            "ppo/returns/mean: -0.8052781820297241\n",
            "ppo/policy/advantages_mean: -0.01098457258194685\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "19it [06:54, 20.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 24.400341033935547\n",
            "ppo/returns/mean: -0.5287930369377136\n",
            "ppo/policy/advantages_mean: 0.009454375132918358\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "20it [07:21, 22.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 29.00598907470703\n",
            "ppo/returns/mean: -0.5821874737739563\n",
            "ppo/policy/advantages_mean: 0.02586403675377369\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "21it [07:44, 22.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 25.563589096069336\n",
            "ppo/returns/mean: -0.5053776502609253\n",
            "ppo/policy/advantages_mean: 0.013322606682777405\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "22it [08:07, 22.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 33.39490509033203\n",
            "ppo/returns/mean: -0.8868480920791626\n",
            "ppo/policy/advantages_mean: -0.0016719978302717209\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23it [08:26, 21.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 21.948013305664062\n",
            "ppo/returns/mean: -0.5030171275138855\n",
            "ppo/policy/advantages_mean: 0.1104646623134613\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24it [08:48, 21.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 27.76030158996582\n",
            "ppo/returns/mean: -0.5849356055259705\n",
            "ppo/policy/advantages_mean: 0.0026756301522254944\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25it [09:11, 22.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 28.596694946289062\n",
            "ppo/returns/mean: -0.5431404709815979\n",
            "ppo/policy/advantages_mean: -0.008462334051728249\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "26it [09:32, 21.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 26.103578567504883\n",
            "ppo/returns/mean: -0.6712157726287842\n",
            "ppo/policy/advantages_mean: -0.020450584590435028\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "27it [09:51, 20.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 21.595600128173828\n",
            "ppo/returns/mean: -0.46690604090690613\n",
            "ppo/policy/advantages_mean: -0.042819976806640625\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "28it [10:13, 21.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 28.05411148071289\n",
            "ppo/returns/mean: -0.6902309656143188\n",
            "ppo/policy/advantages_mean: -0.0003925636410713196\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "29it [10:33, 21.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 21.949338912963867\n",
            "ppo/returns/mean: -0.5126144289970398\n",
            "ppo/policy/advantages_mean: 0.02551381103694439\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "30it [10:53, 20.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 23.4067440032959\n",
            "ppo/returns/mean: -0.5543354749679565\n",
            "ppo/policy/advantages_mean: -0.010505082085728645\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "31it [11:12, 20.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 22.400955200195312\n",
            "ppo/returns/mean: -0.5120266675949097\n",
            "ppo/policy/advantages_mean: -0.0016475096344947815\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "32it [11:31, 19.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 17.427772521972656\n",
            "ppo/returns/mean: -0.2329784333705902\n",
            "ppo/policy/advantages_mean: 0.010102180764079094\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "33it [11:50, 19.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 20.699113845825195\n",
            "ppo/returns/mean: -0.5949006676673889\n",
            "ppo/policy/advantages_mean: 0.019054710865020752\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "34it [12:09, 19.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 24.280460357666016\n",
            "ppo/returns/mean: -0.40117955207824707\n",
            "ppo/policy/advantages_mean: 0.024279162287712097\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "35it [12:29, 19.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 22.491844177246094\n",
            "ppo/returns/mean: -0.5099350214004517\n",
            "ppo/policy/advantages_mean: 0.00351816788315773\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "36it [12:50, 20.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 24.420652389526367\n",
            "ppo/returns/mean: -0.4597208797931671\n",
            "ppo/policy/advantages_mean: -0.0148344486951828\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "37it [13:09, 19.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 19.684364318847656\n",
            "ppo/returns/mean: -0.4147058129310608\n",
            "ppo/policy/advantages_mean: -0.002755414694547653\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "38it [13:28, 19.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 23.68136978149414\n",
            "ppo/returns/mean: -0.521407961845398\n",
            "ppo/policy/advantages_mean: 0.015409027226269245\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "39it [13:47, 19.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 26.064577102661133\n",
            "ppo/returns/mean: -0.6929425001144409\n",
            "ppo/policy/advantages_mean: 0.0006195884197950363\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "40it [14:10, 20.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 21.09670639038086\n",
            "ppo/returns/mean: -0.4097028076648712\n",
            "ppo/policy/advantages_mean: 0.032281965017318726\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "41it [14:29, 20.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 20.582889556884766\n",
            "ppo/returns/mean: -0.41988709568977356\n",
            "ppo/policy/advantages_mean: 0.023099415004253387\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "42it [14:49, 19.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 21.738265991210938\n",
            "ppo/returns/mean: -0.40503981709480286\n",
            "ppo/policy/advantages_mean: -0.021725602447986603\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "43it [15:11, 20.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 25.709617614746094\n",
            "ppo/returns/mean: -0.5860075950622559\n",
            "ppo/policy/advantages_mean: 0.00510358065366745\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "44it [15:30, 20.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 23.090665817260742\n",
            "ppo/returns/mean: -0.5153251886367798\n",
            "ppo/policy/advantages_mean: 0.00832691602408886\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "45it [15:52, 20.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 21.005260467529297\n",
            "ppo/returns/mean: -0.3441448211669922\n",
            "ppo/policy/advantages_mean: 0.012346789240837097\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "46it [16:12, 20.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 24.135122299194336\n",
            "ppo/returns/mean: -0.5627597570419312\n",
            "ppo/policy/advantages_mean: -0.00392127875238657\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "47it [16:31, 20.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 22.5942325592041\n",
            "ppo/returns/mean: -0.5636563301086426\n",
            "ppo/policy/advantages_mean: -0.030923908576369286\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "48it [16:53, 20.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: -341.1752014160156\n",
            "ppo/returns/mean: 23.607318878173828\n",
            "ppo/policy/advantages_mean: 0.01569041609764099\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "49it [17:14, 20.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 23.669525146484375\n",
            "ppo/returns/mean: -0.4850413501262665\n",
            "ppo/policy/advantages_mean: 0.015226350165903568\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "50it [17:35, 21.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objective/kl: 19.973003387451172\n",
            "ppo/returns/mean: -0.2658303678035736\n",
            "ppo/policy/advantages_mean: 0.025714825838804245\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "output_min_length = 100\n",
        "output_max_length = 400\n",
        "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
        "\n",
        "generation_kwargs = {\n",
        "    \"min_length\": 5,\n",
        "    \"top_k\": 0.0,\n",
        "    \"top_p\": 1.0,\n",
        "    \"do_sample\": True\n",
        "}\n",
        "\n",
        "reward_kwargs = {\n",
        "    \"top_k\": None,               # Return all scores\n",
        "    \"function_to_apply\": \"none\", # Get raw logits\n",
        "    \"batch_size\": 16             # Batch inference for GPU efficiency\n",
        "}\n",
        "\n",
        "max_ppo_steps = 50\n",
        "\n",
        "for step, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
        "    if step >= max_ppo_steps:\n",
        "        break\n",
        "\n",
        "    prompt_tensors = batch[\"input_ids\"]\n",
        "\n",
        "    # Generate summaries (responses) using the policy model\n",
        "    summary_tensors = []\n",
        "    for prompt_tensor in prompt_tensors:\n",
        "        max_new_tokens = output_length_sampler()\n",
        "        generation_kwargs[\"max_new_tokens\"] = max_new_tokens\n",
        "\n",
        "        summary = ppo_trainer.generate(prompt_tensor, **generation_kwargs)\n",
        "        summary_tensors.append(summary.squeeze()[-max_new_tokens:])\n",
        "\n",
        "    # Decode the generated summaries\n",
        "    batch[\"response\"] = [tokenizer.decode(r.squeeze(), skip_special_tokens=True) for r in summary_tensors]\n",
        "\n",
        "    # Build joint input (query + response) for reward model\n",
        "    MAX_SEQ_LEN = 512\n",
        "    query_response_pairs = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
        "\n",
        "    # Truncate if necessary and tokenize\n",
        "    query_response_pairs = [\n",
        "        tokenizer.decode(tokenizer(qr, truncation=True, max_length=MAX_SEQ_LEN)[\"input_ids\"])\n",
        "        for qr in query_response_pairs\n",
        "    ]\n",
        "\n",
        "    # Use reward model (e.g. Meta AI's hate speech model) to get toxicity scores\n",
        "    rewards = sentiment_pipe(query_response_pairs, **reward_kwargs)\n",
        "    reward_tensors = [torch.tensor(reward[not_hate_index][\"score\"]) for reward in rewards]\n",
        "\n",
        "    # Run PPO update\n",
        "    stats = ppo_trainer.step(prompt_tensors, summary_tensors, reward_tensors)\n",
        "    ppo_trainer.log_stats(stats, batch, reward_tensors)\n",
        "\n",
        "    # Log key metrics\n",
        "    print(f'objective/kl: {stats[\"objective/kl\"]}')\n",
        "    print(f'ppo/returns/mean: {stats[\"ppo/returns/mean\"]}')\n",
        "    print(f'ppo/policy/advantages_mean: {stats[\"ppo/policy/advantages_mean\"]}')\n",
        "    print('-' * 100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('./ppo_finetuned_model/tokenizer_config.json',\n",
              " './ppo_finetuned_model/special_tokens_map.json',\n",
              " './ppo_finetuned_model/tokenizer.json')"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create save directory\n",
        "import os\n",
        "save_path = \"./ppo_finetuned_model\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Save the model (policy model after PPO fine-tuning)\n",
        "ppo_trainer.model.save_pretrained(save_path)\n",
        "\n",
        "# Save tokenizer\n",
        "tokenizer.save_pretrained(save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7903f5df-a9de-41eb-b239-38bc367b5654",
      "metadata": {
        "id": "7903f5df-a9de-41eb-b239-38bc367b5654"
      },
      "source": [
        "### Evaluate the Model Quantitatively\n",
        "\n",
        "Load the PPO/PEFT model back in from disk and use the test dataset split to evaluate the toxicity score of the RL-fine-tuned model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "11it [00:12,  1.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "toxicity [mean, std] before detox: [0.11854438839310949, 0.07926753609766712]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_path, device_map=device)\n",
        "\n",
        "mean_before_detoxification, std_before_detoxification = evaluate_toxicity(model=ref_model,\n",
        "                                                                          toxicity_evaluator=get_toxicity_score,\n",
        "                                                                          tokenizer=tokenizer,\n",
        "                                                                          dataset=dataset[\"test\"],\n",
        "                                                                          num_samples=10)\n",
        "\n",
        "print(f'toxicity [mean, std] before detox: [{mean_before_detoxification}, {std_before_detoxification}]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "id": "3b093d43-6197-4cc0-b933-29030479a7d0",
      "metadata": {
        "id": "3b093d43-6197-4cc0-b933-29030479a7d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "11it [00:12,  1.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "toxicity [mean, std] after detox: [0.10763244356282732, 0.08202753552020547]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "mean_after_detoxification, std_after_detoxification = evaluate_toxicity(model=ppo_model,\n",
        "                                                                        toxicity_evaluator=get_toxicity_score,\n",
        "                                                                        tokenizer=tokenizer,\n",
        "                                                                        dataset=dataset[\"test\"],\n",
        "                                                                        num_samples=10)\n",
        "print(f'toxicity [mean, std] after detox: [{mean_after_detoxification}, {std_after_detoxification}]')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f42895cc-7bbf-45e1-a7c7-78ee29cd8009",
      "metadata": {
        "id": "f42895cc-7bbf-45e1-a7c7-78ee29cd8009"
      },
      "source": [
        "And compare the toxicity scores of the reference model (before detoxification) and fine-tuned model (after detoxification)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "id": "77cc3af2-6600-4673-874b-917c05247ae3",
      "metadata": {
        "id": "77cc3af2-6600-4673-874b-917c05247ae3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage improvement of toxicity score after detoxification:\n",
            "mean: 9.20%\n",
            "std: -3.48%\n"
          ]
        }
      ],
      "source": [
        "mean_improvement = (mean_before_detoxification - mean_after_detoxification) / mean_before_detoxification\n",
        "std_improvement = (std_before_detoxification - std_after_detoxification) / std_before_detoxification\n",
        "\n",
        "print(f'Percentage improvement of toxicity score after detoxification:')\n",
        "print(f'mean: {mean_improvement*100:.2f}%')\n",
        "print(f'std: {std_improvement*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66030581-b6f7-41d7-a7e6-2466226833be",
      "metadata": {
        "id": "66030581-b6f7-41d7-a7e6-2466226833be"
      },
      "source": [
        "### Evaluate the Model Qualitatively\n",
        "\n",
        "We can compare the original `ref_model` to the fine-tuned/detoxified `ppo_model` using the toxicity evaluator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "id": "22cc8313-20ae-4d32-855e-9b2866fa3085",
      "metadata": {
        "id": "22cc8313-20ae-4d32-855e-9b2866fa3085"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:51<00:00,  2.56s/it]\n"
          ]
        }
      ],
      "source": [
        "batch_size = 20\n",
        "compare_results = {}\n",
        "\n",
        "df_batch = dataset[\"test\"][0:batch_size]\n",
        "\n",
        "compare_results[\"query\"] = df_batch[\"query\"]\n",
        "prompt_tensors = df_batch[\"input_ids\"]\n",
        "\n",
        "summary_tensors_ref = []\n",
        "summary_tensors = []\n",
        "\n",
        "# Get response from ppo and base model.\n",
        "for i in tqdm(range(batch_size)):\n",
        "    gen_len = output_length_sampler()\n",
        "    generation_kwargs[\"max_new_tokens\"] = gen_len\n",
        "\n",
        "    summary = ref_model.generate(\n",
        "        input_ids=torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device),\n",
        "        **generation_kwargs\n",
        "    ).squeeze()[-gen_len:]\n",
        "    summary_tensors_ref.append(summary)\n",
        "\n",
        "    summary = ppo_model.generate(\n",
        "        input_ids=torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device),\n",
        "        **generation_kwargs\n",
        "    ).squeeze()[-gen_len:]\n",
        "    summary_tensors.append(summary)\n",
        "\n",
        "# Decode responses.\n",
        "compare_results[\"response_before\"] = [tokenizer.decode(summary_tensors_ref[i]) for i in range(batch_size)]\n",
        "compare_results[\"response_after\"] = [tokenizer.decode(summary_tensors[i]) for i in range(batch_size)]\n",
        "\n",
        "# Sentiment analysis of query/response pairs before/after.\n",
        "MAX_LEN = 512  # Or 514 depending on your model\n",
        "\n",
        "texts_before = [d + s for d, s in zip(compare_results[\"query\"], compare_results[\"response_before\"])]\n",
        "texts_before = [\n",
        "    tokenizer.decode(tokenizer(t, truncation=True, max_length=MAX_LEN)[\"input_ids\"])\n",
        "    for t in texts_before\n",
        "]\n",
        "rewards_before = sentiment_pipe(texts_before, **reward_kwargs)\n",
        "compare_results[\"reward_before\"] = [reward[not_hate_index][\"score\"] for reward in rewards_before]\n",
        "\n",
        "texts_after = [d + s for d, s in zip(compare_results[\"query\"], compare_results[\"response_after\"])]\n",
        "texts_after = [\n",
        "    tokenizer.decode(tokenizer(t, truncation=True, max_length=MAX_LEN)[\"input_ids\"])\n",
        "    for t in texts_after\n",
        "]\n",
        "rewards_after = sentiment_pipe(texts_after, **reward_kwargs)\n",
        "\n",
        "compare_results[\"reward_after\"] = [reward[not_hate_index][\"score\"] for reward in rewards_after]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65b70892-4c22-4bed-9d1e-9da3f4f0c97f",
      "metadata": {
        "id": "65b70892-4c22-4bed-9d1e-9da3f4f0c97f"
      },
      "source": [
        "Store and review the results in a DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "e06fff0f-9dba-4517-9424-a5ebd81e8f49",
      "metadata": {
        "id": "e06fff0f-9dba-4517-9424-a5ebd81e8f49",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>response_before</th>\n",
              "      <th>response_after</th>\n",
              "      <th>reward_before</th>\n",
              "      <th>reward_after</th>\n",
              "      <th>reward_diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Summarize the following conversation. #Person1#: Ms. Dawson, I need you to take a dictation for me. #Person2#: Yes, sir... #Person1#: This should go out as an intra-office memorandum to all employees by this afternoon. Are you ready? #Person2#: Yes, sir. Go ahead. #Person1#: Attention all staff... Effective immediately, all office communications are restricted to email correspondence and official memos. The use of Instant Message programs by employees during working hours is strictly prohibi...</td>\n",
              "      <td>&lt;pad&gt; Ms. Dawson takes a dictation of new and restrictive procedures to all employees.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; #Person1# wants to tell Ms. Dawson to take a dictation of all employee mail. The code for admitting the communication between employees is first defined by the mediums used and the article to be used during working on the document between employees and the employees. The full code makes sure that the employee who can use Instant Messaging before #4 counters court. Mr. Dawson encourages this.&lt;/s&gt;</td>\n",
              "      <td>1.854992</td>\n",
              "      <td>1.854992</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Summarize the following conversation. #Person1#: Ms. Dawson, I need you to take a dictation for me. #Person2#: Yes, sir... #Person1#: This should go out as an intra-office memorandum to all employees by this afternoon. Are you ready? #Person2#: Yes, sir. Go ahead. #Person1#: Attention all staff... Effective immediately, all office communications are restricted to email correspondence and official memos. The use of Instant Message programs by employees during working hours is strictly prohibi...</td>\n",
              "      <td>&lt;pad&gt; #Person1# asks Ms. Dawson to take a dictation to all employees by this afternoon. To make things clear it should apply to intra-office communications only and to general communications, including outside communications and international communications, the memo will not be enforced. Cull the memo be typed up and distributed.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; Ms. Dawson gives details to staff, encourages use of instant messaging, and encourages staff to regular the wording. The department head reveals one new practice to most sports athletes.&lt;/s&gt;</td>\n",
              "      <td>1.854992</td>\n",
              "      <td>1.854992</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Summarize the following conversation. #Person1#: What's wrong with you? Why are you scratching so much? #Person2#: I feel itchy! I can't stand it anymore! I think I may be coming down with something. I feel lightheaded and weak. #Person1#: Let me have a look. Whoa! Get away from me! #Person2#: What's wrong? #Person1#: I think you have chicken pox! You are contagious! Get away! Don't breathe on me! #Person2#: Maybe it's just a rash or an allergy! We can't be sure until I see a doctor. #Person...</td>\n",
              "      <td>&lt;pad&gt; #Person2# has chicken pox. #Person1# thinks #Person2# have chicken pox, but #Person2# shows signs. #Person1# takes a bath on Friday morning.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; #Person1# thinks #Person2# has chicken pox but #Person2# tells #Person1# this is a biohazard. You really burn!&lt;/s&gt;</td>\n",
              "      <td>0.771682</td>\n",
              "      <td>0.771682</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Summarize the following conversation. #Person1#: I've had it! I am done working for a company that is taking me nowhere! #Person2#: So what are you gonna do? Just quit? #Person1#: That's exactly what I am going to do! I have decided to create my own company! I am going to write up a business plan, get some investors and start working for myself! #Person2#: Have you ever written up a business plan before? #Person1#: Well, no, it can't be that hard! I mean, all you have to do is explain your b...</td>\n",
              "      <td>&lt;pad&gt; #Person1# recently quit following a company that is taking #Person1# nowhere. #Person1# writes a business plan and will start work for himself. #Person2# tells #Person1# to write down a business plan and give away important information like the market analysis, the land policy, forecast earnings and profits. #Person2# feels the most important piece of information needed for the investors are the financial analysis.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; #Person1# decides to start being a business company and wants to make it more accessible. #Person1# lives with the problem and decides to stick to his department jobs.&lt;/s&gt;</td>\n",
              "      <td>1.192065</td>\n",
              "      <td>1.192065</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Summarize the following conversation. #Person1#: I've had it! I am done working for a company that is taking me nowhere! #Person2#: So what are you gonna do? Just quit? #Person1#: That's exactly what I am going to do! I have decided to create my own company! I am going to write up a business plan, get some investors and start working for myself! #Person2#: Have you ever written up a business plan before? #Person1#: Well, no, it can't be that hard! I mean, all you have to do is explain your b...</td>\n",
              "      <td>&lt;pad&gt; #Person1# created a company so she will start working for herself. She helps #Person2# to written a business plan, including an executive summary, company description, and market analysis. A market analysis comprises various variables and checks a firm's finances before beginning to write the project. #Person1# feels misgivings about the initial stage.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; #Person1# wants to create own company and staff, and all the start-up and final stages of a business. #Person1# said to self file the new story and learn the basics of the business plan. #Person2# believes that some top pricing based on factors modify business but #Person1# warns employees that the new business may not be enough.&lt;/s&gt;</td>\n",
              "      <td>1.192065</td>\n",
              "      <td>1.192065</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Summarize the following conversation. #Person1#: I've had it! I am done working for a company that is taking me nowhere! #Person2#: So what are you gonna do? Just quit? #Person1#: That's exactly what I am going to do! I have decided to create my own company! I am going to write up a business plan, get some investors and start working for myself! #Person2#: Have you ever written up a business plan before? #Person1#: Well, no, it can't be that hard! I mean, all you have to do is explain your b...</td>\n",
              "      <td>&lt;pad&gt; #Person2# asks #Person1# how to start a company and is ready to quit the company. #Person1# will help #Person2# write a business plan and get some investors. #Person1# thinks it's too difficult to start a business. As they begin to talk about business, they discuss the financial analysis.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; #Person1# doesn't know much about business, so she turns to asking for advice and then follows some of #Person1#'s advice: I think there's nothing by flailing on the complex process.&lt;/s&gt;</td>\n",
              "      <td>1.192068</td>\n",
              "      <td>1.192068</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Summarize the following conversation. #Person1#: This Olympic park is so big! #Person2#: Yes. Now we are in the Olympic stadium, the center of this park. #Person1#: Splendid! When is it gonna be finished? #Person2#: The whole stadium is to be finished this June. #Person1#: How many seats are there in the stand? #Person2#: Oh, there are 5000 seats in total. #Person1#: I didn ' t know it would be so big! #Person2#: It is! Look there, those are the tracks. And the jumping pit is over there. #Pe...</td>\n",
              "      <td>&lt;pad&gt; #Person2# tells #Person1# that the Olympic park is huge. #Person1# is excited about the big number of seats of the stadium and gets excited.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; @Misy is from Mexico. #Person2# shows some pictures of how impressive the Olympic stadium is and their signs are amazing.&lt;/s&gt;</td>\n",
              "      <td>1.021055</td>\n",
              "      <td>1.021055</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Summarize the following conversation. #Person1#: This Olympic park is so big! #Person2#: Yes. Now we are in the Olympic stadium, the center of this park. #Person1#: Splendid! When is it gonna be finished? #Person2#: The whole stadium is to be finished this June. #Person1#: How many seats are there in the stand? #Person2#: Oh, there are 5000 seats in total. #Person1#: I didn ' t know it would be so big! #Person2#: It is! Look there, those are the tracks. And the jumping pit is over there. #Pe...</td>\n",
              "      <td>&lt;pad&gt; #Person1# plays for #Person2#'s friends, others, at the Olympic stadium. #Person1# likes the place and tells #Person2# about this sports park.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; #Person2# tells #Person1# that there are 5000 seats in the Olympic stadium as well as the cacha with the matches. #Person1# and #Person2# put many signs with English translations for tourists.&lt;/s&gt;</td>\n",
              "      <td>1.021055</td>\n",
              "      <td>1.021055</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Summarize the following conversation. #Person1#: This Olympic park is so big! #Person2#: Yes. Now we are in the Olympic stadium, the center of this park. #Person1#: Splendid! When is it gonna be finished? #Person2#: The whole stadium is to be finished this June. #Person1#: How many seats are there in the stand? #Person2#: Oh, there are 5000 seats in total. #Person1#: I didn ' t know it would be so big! #Person2#: It is! Look there, those are the tracks. And the jumping pit is over there. #Pe...</td>\n",
              "      <td>&lt;pad&gt; #Person2# tells #Person1# about the Olympic park in which they are in the stadium. They see the queues and how big the stadium is. They think very peaceful.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; #Person2# shows a huge Olympic park located in the guide park. The whole stadium is to be finished this June for the duration of the competition and there are a lot of places,\"no climbing\" to reach.&lt;/s&gt;</td>\n",
              "      <td>1.021055</td>\n",
              "      <td>1.021055</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Summarize the following conversation. #Person1#: Happy Birthday, this is for you, Brian. #Person2#: I'm so happy you remember, please come in and enjoy the party. Everyone's here, I'm sure you have a good time. #Person1#: Brian, may I have a pleasure to have a dance with you? #Person2#: Ok. #Person1#: This is really wonderful party. #Person2#: Yes, you are always popular with everyone. and you look very pretty today. #Person1#: Thanks, that's very kind of you to say. I hope my necklace goes ...</td>\n",
              "      <td>&lt;pad&gt; Brian remembers his birthday from a party. He invites everyone to join him and the party went really well. Brian often asks the author about his fellow party-stars and share a drink together.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; Brian came to the birthday party and apologized for his problems and smiles.&lt;/s&gt;</td>\n",
              "      <td>0.990319</td>\n",
              "      <td>0.990319</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Summarize the following conversation. #Person1#: Happy Birthday, this is for you, Brian. #Person2#: I'm so happy you remember, please come in and enjoy the party. Everyone's here, I'm sure you have a good time. #Person1#: Brian, may I have a pleasure to have a dance with you? #Person2#: Ok. #Person1#: This is really wonderful party. #Person2#: Yes, you are always popular with everyone. and you look very pretty today. #Person1#: Thanks, that's very kind of you to say. I hope my necklace goes ...</td>\n",
              "      <td>&lt;pad&gt; Brian remembers Brian and invites him to enjoy the party. Brian also wants to have a dance and asks #Person2# to come with them.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; Brian Jose wanted to save by a dance with her. Mariu took photos of her with her and loved her looks. Mariu suggests they had a glass together to celebrate their birthday.&lt;/s&gt;</td>\n",
              "      <td>0.990319</td>\n",
              "      <td>0.990319</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Summarize the following conversation. #Person1#: Happy Birthday, this is for you, Brian. #Person2#: I'm so happy you remember, please come in and enjoy the party. Everyone's here, I'm sure you have a good time. #Person1#: Brian, may I have a pleasure to have a dance with you? #Person2#: Ok. #Person1#: This is really wonderful party. #Person2#: Yes, you are always popular with everyone. and you look very pretty today. #Person1#: Thanks, that's very kind of you to say. I hope my necklace goes ...</td>\n",
              "      <td>&lt;pad&gt; Brian is happy that he remembered people's birthday and enjoyed the dance at the party he attended. Melissa thinks Brian looks pretty today and they should have a drink together to celebrate Brian's birthday.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; #Person1#'s birthday is next Friday and party will be happy to celebrate with co-star Brian. #Person2# says that Brian is going to have a dance between him and Brian. It is a great party and he is showing off his event like they celebrate when he got his wife on thy birthday.&lt;/s&gt;</td>\n",
              "      <td>0.990319</td>\n",
              "      <td>0.990319</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Summarize the following conversation. #Person1#: Kate, you never believe what's happened. #Person2#: What do you mean? #Person1#: Masha and Hero are getting divorced. #Person2#: You are kidding. What happened? #Person1#: Well, I don't really know, but I heard that they are having a separation for 2 months, and filed for divorce. #Person2#: That's really surprising. I always thought they are well matched. What about the kids? Who get custody? #Person1#: Masha, it seems quiet and makable, no q...</td>\n",
              "      <td>&lt;pad&gt; Kate describes to Kate that Masha and Hero will get divorced in two months due to a separation. Kate's surprised because she knows the husband gets custody of the kids after the separation, so she has no doubts about when the divorce will be final.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; Kate comes down with a bad sentence to tell her about just what happened to Masha and Hero. Email is never received.&lt;/s&gt;</td>\n",
              "      <td>0.661180</td>\n",
              "      <td>0.661180</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Summarize the following conversation. #Person1#: Kate, you never believe what's happened. #Person2#: What do you mean? #Person1#: Masha and Hero are getting divorced. #Person2#: You are kidding. What happened? #Person1#: Well, I don't really know, but I heard that they are having a separation for 2 months, and filed for divorce. #Person2#: That's really surprising. I always thought they are well matched. What about the kids? Who get custody? #Person1#: Masha, it seems quiet and makable, no q...</td>\n",
              "      <td>&lt;pad&gt; Kate comforts Kate about their divorce. She tells Kate that it's surprising that Masha and Hero are getting divorced and #Person1# can't believe it.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; Kate is surprised and confused when she heard maybe Masha and Hero are going to divorce. Back to her tense. Now she finds out much later but she's not convinced.&lt;/s&gt;</td>\n",
              "      <td>0.661180</td>\n",
              "      <td>0.661180</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Summarize the following conversation. #Person1#: Kate, you never believe what's happened. #Person2#: What do you mean? #Person1#: Masha and Hero are getting divorced. #Person2#: You are kidding. What happened? #Person1#: Well, I don't really know, but I heard that they are having a separation for 2 months, and filed for divorce. #Person2#: That's really surprising. I always thought they are well matched. What about the kids? Who get custody? #Person1#: Masha, it seems quiet and makable, no q...</td>\n",
              "      <td>&lt;pad&gt; Kate tells Kate there is a wedding in which Madha and Masha are getting divorced. #Person1# thinks they are the perfect couple and they would divorce in the New Year.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; Kate says they are getting divorced and they have a wok deal in terms of family, custody and custody by a marriage, and they are married because they're related to understanding each other, which elevates clarity. Finds they're in a happy marriage, but not according to wedding premiere.&lt;/s&gt;</td>\n",
              "      <td>0.661180</td>\n",
              "      <td>0.661180</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Summarize the following conversation. #Person1#: You're finally here! What took so long? #Person2#: I got stuck in traffic again. There was a terrible traffic jam near the Carrefour intersection. #Person1#: It's always rather congested down there during rush hour. Maybe you should try to find a different route to get home. #Person2#: I don't think it can be avoided, to be honest. #Person1#: perhaps it would be better if you started taking public transport system to work. #Person2#: I think i...</td>\n",
              "      <td>&lt;pad&gt; #Person2# asked #Person1# why there's a traffic jam in the center of the city. #Person1# thinks a public transportation to work can bring some liberation for the environment. #Person2# feels bad about the pollution problem from the car, and suggests to start biking to work when a nicer day. #Person2# wants to quit driving to work.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; #Person2# got stuck in traffic and was unhappy because it was dominated by cars just because they went to work. Now the people are changing its procedure to join the service because it's also less stressful for the environment. It's not good for the environment.&lt;/s&gt;</td>\n",
              "      <td>2.513169</td>\n",
              "      <td>2.513169</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Summarize the following conversation. #Person1#: You're finally here! What took so long? #Person2#: I got stuck in traffic again. There was a terrible traffic jam near the Carrefour intersection. #Person1#: It's always rather congested down there during rush hour. Maybe you should try to find a different route to get home. #Person2#: I don't think it can be avoided, to be honest. #Person1#: perhaps it would be better if you started taking public transport system to work. #Person2#: I think i...</td>\n",
              "      <td>&lt;pad&gt; #Person2# was stuck in traffic on the Carrefour intersection. #Person1# proposes to start taking public transport to work and #Person2#'ll take the subway to work. #Person1# suggests cycling to work because there's less stress than driving. #Person1# suggests #Person2# will help #Person2# with biking until the traffic is better to leave for another day.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; #Person2# was in a traffic jam at the Carrefour intersection. It is rough down when the traffic jam is late in the morning when the cars are driving. #Person2# will have to take a bus to get home. #Person1# suggests taking public transport to work, but it's not easy.&lt;/s&gt;</td>\n",
              "      <td>2.513169</td>\n",
              "      <td>2.513169</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Summarize the following conversation. #Person1#: You're finally here! What took so long? #Person2#: I got stuck in traffic again. There was a terrible traffic jam near the Carrefour intersection. #Person1#: It's always rather congested down there during rush hour. Maybe you should try to find a different route to get home. #Person2#: I don't think it can be avoided, to be honest. #Person1#: perhaps it would be better if you started taking public transport system to work. #Person2#: I think i...</td>\n",
              "      <td>&lt;pad&gt; #Person2# says #Person2# is stuck in a traffic jam and suggests #Person2# switch routes to work. #Person1# recommends a public transport system to work, \"originated the cramps of the car and expressed much concern for [his car an thing]'s pollution problem. #Person1# recommends a bicycle to work and #Person2# doesn't like the job anymore.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; #Person2# was stopped in traffic jam near the Carren Palazzo intersection. #Person1# thinks it would be better to look into public HVC means and requests how to take a bus to work because everything in the day will be easier for the year.&lt;/s&gt;</td>\n",
              "      <td>2.513169</td>\n",
              "      <td>2.513169</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Summarize the following conversation. #Person1#: Ms. Dawson, I need you to take a dictation for me. #Person2#: Yes, sir... #Person1#: This should go out as an intra-office memorandum to all employees by this afternoon. Are you ready? #Person2#: Yes, sir. Go ahead. #Person1#: Attention all staff... Effective immediately, all office communications are restricted to email correspondence and official memos. The use of Instant Message programs by employees during working hours is strictly prohibi...</td>\n",
              "      <td>&lt;pad&gt; Ms. Dawson informs #Person1# of the directive passed out as an intra-office memo on Monday. #Person1# insists on completely exclusive use of Instant Message programs. The office is forbidden from utilizing instant messaging, including speeches, and talks to David Mays.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; #Person2# recommends the use of instant messaging to all employees and leaves the memo. But Danny criticizes the use of instant messaging to communicate with clients and invites employees to take correction or deletion.&lt;/s&gt;</td>\n",
              "      <td>1.854992</td>\n",
              "      <td>1.854992</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Summarize the following conversation. #Person1#: What's wrong with you? Why are you scratching so much? #Person2#: I feel itchy! I can't stand it anymore! I think I may be coming down with something. I feel lightheaded and weak. #Person1#: Let me have a look. Whoa! Get away from me! #Person2#: What's wrong? #Person1#: I think you have chicken pox! You are contagious! Get away! Don't breathe on me! #Person2#: Maybe it's just a rash or an allergy! We can't be sure until I see a doctor. #Person...</td>\n",
              "      <td>&lt;pad&gt; #Person2#'s scratching so much and thinks #Person2# may be coming down with something. #Person1# advises #Person2# not to breathe on #Person2# and advises #Person2# to take an oatmeal bath.&lt;/s&gt;</td>\n",
              "      <td>&lt;pad&gt; #Person2# is scratching so much and feels bad. #Person1# tells everyone to be very culim based on #Person2#'s lack of attention to scratch.&lt;/s&gt;</td>\n",
              "      <td>0.771682</td>\n",
              "      <td>0.771682</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  query  \\\n",
              "0   Summarize the following conversation. #Person1#: Ms. Dawson, I need you to take a dictation for me. #Person2#: Yes, sir... #Person1#: This should go out as an intra-office memorandum to all employees by this afternoon. Are you ready? #Person2#: Yes, sir. Go ahead. #Person1#: Attention all staff... Effective immediately, all office communications are restricted to email correspondence and official memos. The use of Instant Message programs by employees during working hours is strictly prohibi...   \n",
              "1   Summarize the following conversation. #Person1#: Ms. Dawson, I need you to take a dictation for me. #Person2#: Yes, sir... #Person1#: This should go out as an intra-office memorandum to all employees by this afternoon. Are you ready? #Person2#: Yes, sir. Go ahead. #Person1#: Attention all staff... Effective immediately, all office communications are restricted to email correspondence and official memos. The use of Instant Message programs by employees during working hours is strictly prohibi...   \n",
              "2   Summarize the following conversation. #Person1#: What's wrong with you? Why are you scratching so much? #Person2#: I feel itchy! I can't stand it anymore! I think I may be coming down with something. I feel lightheaded and weak. #Person1#: Let me have a look. Whoa! Get away from me! #Person2#: What's wrong? #Person1#: I think you have chicken pox! You are contagious! Get away! Don't breathe on me! #Person2#: Maybe it's just a rash or an allergy! We can't be sure until I see a doctor. #Person...   \n",
              "3   Summarize the following conversation. #Person1#: I've had it! I am done working for a company that is taking me nowhere! #Person2#: So what are you gonna do? Just quit? #Person1#: That's exactly what I am going to do! I have decided to create my own company! I am going to write up a business plan, get some investors and start working for myself! #Person2#: Have you ever written up a business plan before? #Person1#: Well, no, it can't be that hard! I mean, all you have to do is explain your b...   \n",
              "4   Summarize the following conversation. #Person1#: I've had it! I am done working for a company that is taking me nowhere! #Person2#: So what are you gonna do? Just quit? #Person1#: That's exactly what I am going to do! I have decided to create my own company! I am going to write up a business plan, get some investors and start working for myself! #Person2#: Have you ever written up a business plan before? #Person1#: Well, no, it can't be that hard! I mean, all you have to do is explain your b...   \n",
              "5   Summarize the following conversation. #Person1#: I've had it! I am done working for a company that is taking me nowhere! #Person2#: So what are you gonna do? Just quit? #Person1#: That's exactly what I am going to do! I have decided to create my own company! I am going to write up a business plan, get some investors and start working for myself! #Person2#: Have you ever written up a business plan before? #Person1#: Well, no, it can't be that hard! I mean, all you have to do is explain your b...   \n",
              "6   Summarize the following conversation. #Person1#: This Olympic park is so big! #Person2#: Yes. Now we are in the Olympic stadium, the center of this park. #Person1#: Splendid! When is it gonna be finished? #Person2#: The whole stadium is to be finished this June. #Person1#: How many seats are there in the stand? #Person2#: Oh, there are 5000 seats in total. #Person1#: I didn ' t know it would be so big! #Person2#: It is! Look there, those are the tracks. And the jumping pit is over there. #Pe...   \n",
              "7   Summarize the following conversation. #Person1#: This Olympic park is so big! #Person2#: Yes. Now we are in the Olympic stadium, the center of this park. #Person1#: Splendid! When is it gonna be finished? #Person2#: The whole stadium is to be finished this June. #Person1#: How many seats are there in the stand? #Person2#: Oh, there are 5000 seats in total. #Person1#: I didn ' t know it would be so big! #Person2#: It is! Look there, those are the tracks. And the jumping pit is over there. #Pe...   \n",
              "8   Summarize the following conversation. #Person1#: This Olympic park is so big! #Person2#: Yes. Now we are in the Olympic stadium, the center of this park. #Person1#: Splendid! When is it gonna be finished? #Person2#: The whole stadium is to be finished this June. #Person1#: How many seats are there in the stand? #Person2#: Oh, there are 5000 seats in total. #Person1#: I didn ' t know it would be so big! #Person2#: It is! Look there, those are the tracks. And the jumping pit is over there. #Pe...   \n",
              "9   Summarize the following conversation. #Person1#: Happy Birthday, this is for you, Brian. #Person2#: I'm so happy you remember, please come in and enjoy the party. Everyone's here, I'm sure you have a good time. #Person1#: Brian, may I have a pleasure to have a dance with you? #Person2#: Ok. #Person1#: This is really wonderful party. #Person2#: Yes, you are always popular with everyone. and you look very pretty today. #Person1#: Thanks, that's very kind of you to say. I hope my necklace goes ...   \n",
              "10  Summarize the following conversation. #Person1#: Happy Birthday, this is for you, Brian. #Person2#: I'm so happy you remember, please come in and enjoy the party. Everyone's here, I'm sure you have a good time. #Person1#: Brian, may I have a pleasure to have a dance with you? #Person2#: Ok. #Person1#: This is really wonderful party. #Person2#: Yes, you are always popular with everyone. and you look very pretty today. #Person1#: Thanks, that's very kind of you to say. I hope my necklace goes ...   \n",
              "11  Summarize the following conversation. #Person1#: Happy Birthday, this is for you, Brian. #Person2#: I'm so happy you remember, please come in and enjoy the party. Everyone's here, I'm sure you have a good time. #Person1#: Brian, may I have a pleasure to have a dance with you? #Person2#: Ok. #Person1#: This is really wonderful party. #Person2#: Yes, you are always popular with everyone. and you look very pretty today. #Person1#: Thanks, that's very kind of you to say. I hope my necklace goes ...   \n",
              "12  Summarize the following conversation. #Person1#: Kate, you never believe what's happened. #Person2#: What do you mean? #Person1#: Masha and Hero are getting divorced. #Person2#: You are kidding. What happened? #Person1#: Well, I don't really know, but I heard that they are having a separation for 2 months, and filed for divorce. #Person2#: That's really surprising. I always thought they are well matched. What about the kids? Who get custody? #Person1#: Masha, it seems quiet and makable, no q...   \n",
              "13  Summarize the following conversation. #Person1#: Kate, you never believe what's happened. #Person2#: What do you mean? #Person1#: Masha and Hero are getting divorced. #Person2#: You are kidding. What happened? #Person1#: Well, I don't really know, but I heard that they are having a separation for 2 months, and filed for divorce. #Person2#: That's really surprising. I always thought they are well matched. What about the kids? Who get custody? #Person1#: Masha, it seems quiet and makable, no q...   \n",
              "14  Summarize the following conversation. #Person1#: Kate, you never believe what's happened. #Person2#: What do you mean? #Person1#: Masha and Hero are getting divorced. #Person2#: You are kidding. What happened? #Person1#: Well, I don't really know, but I heard that they are having a separation for 2 months, and filed for divorce. #Person2#: That's really surprising. I always thought they are well matched. What about the kids? Who get custody? #Person1#: Masha, it seems quiet and makable, no q...   \n",
              "15  Summarize the following conversation. #Person1#: You're finally here! What took so long? #Person2#: I got stuck in traffic again. There was a terrible traffic jam near the Carrefour intersection. #Person1#: It's always rather congested down there during rush hour. Maybe you should try to find a different route to get home. #Person2#: I don't think it can be avoided, to be honest. #Person1#: perhaps it would be better if you started taking public transport system to work. #Person2#: I think i...   \n",
              "16  Summarize the following conversation. #Person1#: You're finally here! What took so long? #Person2#: I got stuck in traffic again. There was a terrible traffic jam near the Carrefour intersection. #Person1#: It's always rather congested down there during rush hour. Maybe you should try to find a different route to get home. #Person2#: I don't think it can be avoided, to be honest. #Person1#: perhaps it would be better if you started taking public transport system to work. #Person2#: I think i...   \n",
              "17  Summarize the following conversation. #Person1#: You're finally here! What took so long? #Person2#: I got stuck in traffic again. There was a terrible traffic jam near the Carrefour intersection. #Person1#: It's always rather congested down there during rush hour. Maybe you should try to find a different route to get home. #Person2#: I don't think it can be avoided, to be honest. #Person1#: perhaps it would be better if you started taking public transport system to work. #Person2#: I think i...   \n",
              "18  Summarize the following conversation. #Person1#: Ms. Dawson, I need you to take a dictation for me. #Person2#: Yes, sir... #Person1#: This should go out as an intra-office memorandum to all employees by this afternoon. Are you ready? #Person2#: Yes, sir. Go ahead. #Person1#: Attention all staff... Effective immediately, all office communications are restricted to email correspondence and official memos. The use of Instant Message programs by employees during working hours is strictly prohibi...   \n",
              "19  Summarize the following conversation. #Person1#: What's wrong with you? Why are you scratching so much? #Person2#: I feel itchy! I can't stand it anymore! I think I may be coming down with something. I feel lightheaded and weak. #Person1#: Let me have a look. Whoa! Get away from me! #Person2#: What's wrong? #Person1#: I think you have chicken pox! You are contagious! Get away! Don't breathe on me! #Person2#: Maybe it's just a rash or an allergy! We can't be sure until I see a doctor. #Person...   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                 response_before  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                                     <pad> Ms. Dawson takes a dictation of new and restrictive procedures to all employees.</s>   \n",
              "1                                                                                               <pad> #Person1# asks Ms. Dawson to take a dictation to all employees by this afternoon. To make things clear it should apply to intra-office communications only and to general communications, including outside communications and international communications, the memo will not be enforced. Cull the memo be typed up and distributed.</s>   \n",
              "2                                                                                                                                                                                                                                                                                         <pad> #Person2# has chicken pox. #Person1# thinks #Person2# have chicken pox, but #Person2# shows signs. #Person1# takes a bath on Friday morning.</s>   \n",
              "3   <pad> #Person1# recently quit following a company that is taking #Person1# nowhere. #Person1# writes a business plan and will start work for himself. #Person2# tells #Person1# to write down a business plan and give away important information like the market analysis, the land policy, forecast earnings and profits. #Person2# feels the most important piece of information needed for the investors are the financial analysis.</s>   \n",
              "4                                                                   <pad> #Person1# created a company so she will start working for herself. She helps #Person2# to written a business plan, including an executive summary, company description, and market analysis. A market analysis comprises various variables and checks a firm's finances before beginning to write the project. #Person1# feels misgivings about the initial stage.</s>   \n",
              "5                                                                                                                                    <pad> #Person2# asks #Person1# how to start a company and is ready to quit the company. #Person1# will help #Person2# write a business plan and get some investors. #Person1# thinks it's too difficult to start a business. As they begin to talk about business, they discuss the financial analysis.</s>   \n",
              "6                                                                                                                                                                                                                                                                                         <pad> #Person2# tells #Person1# that the Olympic park is huge. #Person1# is excited about the big number of seats of the stadium and gets excited.</s>   \n",
              "7                                                                                                                                                                                                                                                                                       <pad> #Person1# plays for #Person2#'s friends, others, at the Olympic stadium. #Person1# likes the place and tells #Person2# about this sports park.</s>   \n",
              "8                                                                                                                                                                                                                                                                         <pad> #Person2# tells #Person1# about the Olympic park in which they are in the stadium. They see the queues and how big the stadium is. They think very peaceful.</s>   \n",
              "9                                                                                                                                                                                                                                      <pad> Brian remembers his birthday from a party. He invites everyone to join him and the party went really well. Brian often asks the author about his fellow party-stars and share a drink together.</s>   \n",
              "10                                                                                                                                                                                                                                                                                                    <pad> Brian remembers Brian and invites him to enjoy the party. Brian also wants to have a dance and asks #Person2# to come with them.</s>   \n",
              "11                                                                                                                                                                                                                    <pad> Brian is happy that he remembered people's birthday and enjoyed the dance at the party he attended. Melissa thinks Brian looks pretty today and they should have a drink together to celebrate Brian's birthday.</s>   \n",
              "12                                                                                                                                                                            <pad> Kate describes to Kate that Masha and Hero will get divorced in two months due to a separation. Kate's surprised because she knows the husband gets custody of the kids after the separation, so she has no doubts about when the divorce will be final.</s>   \n",
              "13                                                                                                                                                                                                                                                                                <pad> Kate comforts Kate about their divorce. She tells Kate that it's surprising that Masha and Hero are getting divorced and #Person1# can't believe it.</s>   \n",
              "14                                                                                                                                                                                                                                                              <pad> Kate tells Kate there is a wedding in which Madha and Masha are getting divorced. #Person1# thinks they are the perfect couple and they would divorce in the New Year.</s>   \n",
              "15                                                                                        <pad> #Person2# asked #Person1# why there's a traffic jam in the center of the city. #Person1# thinks a public transportation to work can bring some liberation for the environment. #Person2# feels bad about the pollution problem from the car, and suggests to start biking to work when a nicer day. #Person2# wants to quit driving to work.</s>   \n",
              "16                                                                 <pad> #Person2# was stuck in traffic on the Carrefour intersection. #Person1# proposes to start taking public transport to work and #Person2#'ll take the subway to work. #Person1# suggests cycling to work because there's less stress than driving. #Person1# suggests #Person2# will help #Person2# with biking until the traffic is better to leave for another day.</s>   \n",
              "17                                                                                <pad> #Person2# says #Person2# is stuck in a traffic jam and suggests #Person2# switch routes to work. #Person1# recommends a public transport system to work, \"originated the cramps of the car and expressed much concern for [his car an thing]'s pollution problem. #Person1# recommends a bicycle to work and #Person2# doesn't like the job anymore.</s>   \n",
              "18                                                                                                                                                       <pad> Ms. Dawson informs #Person1# of the directive passed out as an intra-office memo on Monday. #Person1# insists on completely exclusive use of Instant Message programs. The office is forbidden from utilizing instant messaging, including speeches, and talks to David Mays.</s>   \n",
              "19                                                                                                                                                                                                                                       <pad> #Person2#'s scratching so much and thinks #Person2# may be coming down with something. #Person1# advises #Person2# not to breathe on #Person2# and advises #Person2# to take an oatmeal bath.</s>   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                          response_after  \\\n",
              "0   <pad> #Person1# wants to tell Ms. Dawson to take a dictation of all employee mail. The code for admitting the communication between employees is first defined by the mediums used and the article to be used during working on the document between employees and the employees. The full code makes sure that the employee who can use Instant Messaging before #4 counters court. Mr. Dawson encourages this.</s>   \n",
              "1                                                                                                                                                                                                                   <pad> Ms. Dawson gives details to staff, encourages use of instant messaging, and encourages staff to regular the wording. The department head reveals one new practice to most sports athletes.</s>   \n",
              "2                                                                                                                                                                                                                                                                                               <pad> #Person1# thinks #Person2# has chicken pox but #Person2# tells #Person1# this is a biohazard. You really burn!</s>   \n",
              "3                                                                                                                                                                                                                                      <pad> #Person1# decides to start being a business company and wants to make it more accessible. #Person1# lives with the problem and decides to stick to his department jobs.</s>   \n",
              "4                                                                  <pad> #Person1# wants to create own company and staff, and all the start-up and final stages of a business. #Person1# said to self file the new story and learn the basics of the business plan. #Person2# believes that some top pricing based on factors modify business but #Person1# warns employees that the new business may not be enough.</s>   \n",
              "5                                                                                                                                                                                                                       <pad> #Person1# doesn't know much about business, so she turns to asking for advice and then follows some of #Person1#'s advice: I think there's nothing by flailing on the complex process.</s>   \n",
              "6                                                                                                                                                                                                                                                                                    <pad> @Misy is from Mexico. #Person2# shows some pictures of how impressive the Olympic stadium is and their signs are amazing.</s>   \n",
              "7                                                                                                                                                                                                             <pad> #Person2# tells #Person1# that there are 5000 seats in the Olympic stadium as well as the cacha with the matches. #Person1# and #Person2# put many signs with English translations for tourists.</s>   \n",
              "8                                                                                                                                                                                                       <pad> #Person2# shows a huge Olympic park located in the guide park. The whole stadium is to be finished this June for the duration of the competition and there are a lot of places,\"no climbing\" to reach.</s>   \n",
              "9                                                                                                                                                                                                                                                                                                                                 <pad> Brian came to the birthday party and apologized for his problems and smiles.</s>   \n",
              "10                                                                                                                                                                                                                                 <pad> Brian Jose wanted to save by a dance with her. Mariu took photos of her with her and loved her looks. Mariu suggests they had a glass together to celebrate their birthday.</s>   \n",
              "11                                                                                                                        <pad> #Person1#'s birthday is next Friday and party will be happy to celebrate with co-star Brian. #Person2# says that Brian is going to have a dance between him and Brian. It is a great party and he is showing off his event like they celebrate when he got his wife on thy birthday.</s>   \n",
              "12                                                                                                                                                                                                                                                                                        <pad> Kate comes down with a bad sentence to tell her about just what happened to Masha and Hero. Email is never received.</s>   \n",
              "13                                                                                                                                                                                                                                           <pad> Kate is surprised and confused when she heard maybe Masha and Hero are going to divorce. Back to her tense. Now she finds out much later but she's not convinced.</s>   \n",
              "14                                                                                                             <pad> Kate says they are getting divorced and they have a wok deal in terms of family, custody and custody by a marriage, and they are married because they're related to understanding each other, which elevates clarity. Finds they're in a happy marriage, but not according to wedding premiere.</s>   \n",
              "15                                                                                                                                      <pad> #Person2# got stuck in traffic and was unhappy because it was dominated by cars just because they went to work. Now the people are changing its procedure to join the service because it's also less stressful for the environment. It's not good for the environment.</s>   \n",
              "16                                                                                                                                 <pad> #Person2# was in a traffic jam at the Carrefour intersection. It is rough down when the traffic jam is late in the morning when the cars are driving. #Person2# will have to take a bus to get home. #Person1# suggests taking public transport to work, but it's not easy.</s>   \n",
              "17                                                                                                                                                              <pad> #Person2# was stopped in traffic jam near the Carren Palazzo intersection. #Person1# thinks it would be better to look into public HVC means and requests how to take a bus to work because everything in the day will be easier for the year.</s>   \n",
              "18                                                                                                                                                                                 <pad> #Person2# recommends the use of instant messaging to all employees and leaves the memo. But Danny criticizes the use of instant messaging to communicate with clients and invites employees to take correction or deletion.</s>   \n",
              "19                                                                                                                                                                                                                                                                 <pad> #Person2# is scratching so much and feels bad. #Person1# tells everyone to be very culim based on #Person2#'s lack of attention to scratch.</s>   \n",
              "\n",
              "    reward_before  reward_after  reward_diff  \n",
              "0        1.854992      1.854992          0.0  \n",
              "1        1.854992      1.854992          0.0  \n",
              "2        0.771682      0.771682          0.0  \n",
              "3        1.192065      1.192065          0.0  \n",
              "4        1.192065      1.192065          0.0  \n",
              "5        1.192068      1.192068          0.0  \n",
              "6        1.021055      1.021055          0.0  \n",
              "7        1.021055      1.021055          0.0  \n",
              "8        1.021055      1.021055          0.0  \n",
              "9        0.990319      0.990319          0.0  \n",
              "10       0.990319      0.990319          0.0  \n",
              "11       0.990319      0.990319          0.0  \n",
              "12       0.661180      0.661180          0.0  \n",
              "13       0.661180      0.661180          0.0  \n",
              "14       0.661180      0.661180          0.0  \n",
              "15       2.513169      2.513169          0.0  \n",
              "16       2.513169      2.513169          0.0  \n",
              "17       2.513169      2.513169          0.0  \n",
              "18       1.854992      1.854992          0.0  \n",
              "19       0.771682      0.771682          0.0  "
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.set_option('display.max_colwidth', 500)\n",
        "df_compare_results = pd.DataFrame(compare_results)\n",
        "df_compare_results[\"reward_diff\"] = df_compare_results['reward_after'] - df_compare_results['reward_before']\n",
        "df_compare_results_sorted = df_compare_results.sort_values(by=['reward_diff'], ascending=False).reset_index(drop=True)\n",
        "df_compare_results_sorted"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7fb2477-f719-48de-b169-0607d355a8f6",
      "metadata": {
        "id": "e7fb2477-f719-48de-b169-0607d355a8f6"
      },
      "source": [
        "**Looking at the reward mean/median of the generated sequences we can observe a significant difference!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "availableInstances": [
      {
        "_defaultOrder": 0,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 4,
        "name": "ml.t3.medium",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 1,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.t3.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 2,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.t3.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 3,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.t3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 4,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.m5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 5,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.m5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 6,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.m5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 7,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.m5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 8,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.m5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 9,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.m5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 10,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.m5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 11,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.m5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 12,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.m5d.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 13,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.m5d.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 14,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.m5d.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 15,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.m5d.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 16,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.m5d.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 17,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.m5d.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 18,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.m5d.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 19,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.m5d.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 20,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": true,
        "memoryGiB": 0,
        "name": "ml.geospatial.interactive",
        "supportedImageNames": [
          "sagemaker-geospatial-v1-0"
        ],
        "vcpuNum": 0
      },
      {
        "_defaultOrder": 21,
        "_isFastLaunch": true,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 4,
        "name": "ml.c5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 22,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.c5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 23,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.c5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 24,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.c5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 25,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 72,
        "name": "ml.c5.9xlarge",
        "vcpuNum": 36
      },
      {
        "_defaultOrder": 26,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 96,
        "name": "ml.c5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 27,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 144,
        "name": "ml.c5.18xlarge",
        "vcpuNum": 72
      },
      {
        "_defaultOrder": 28,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.c5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 29,
        "_isFastLaunch": true,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.g4dn.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 30,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.g4dn.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 31,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.g4dn.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 32,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.g4dn.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 33,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.g4dn.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 34,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.g4dn.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 35,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 61,
        "name": "ml.p3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 36,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 244,
        "name": "ml.p3.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 37,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 488,
        "name": "ml.p3.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 38,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.p3dn.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 39,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.r5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 40,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.r5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 41,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.r5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 42,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.r5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 43,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.r5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 44,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.r5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 45,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 512,
        "name": "ml.r5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 46,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.r5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 47,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.g5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 48,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.g5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 49,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.g5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 50,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.g5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 51,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.g5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 52,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.g5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 53,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.g5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 54,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.g5.48xlarge",
        "vcpuNum": 192
      },
      {
        "_defaultOrder": 55,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 1152,
        "name": "ml.p4d.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 56,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 1152,
        "name": "ml.p4de.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 57,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.trn1.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 58,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 512,
        "name": "ml.trn1.32xlarge",
        "vcpuNum": 128
      },
      {
        "_defaultOrder": 59,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 512,
        "name": "ml.trn1n.32xlarge",
        "vcpuNum": 128
      }
    ],
    "colab": {
      "provenance": []
    },
    "instance_type": "ml.m5.2xlarge",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}